
 ♫ Instrumental intro music ♫
 Winning is making a series of good decisions. A well-executed plan that can lead to eventual success.
 Recent work in artificial intelligence has shown that reinforcement learning can be a powerful tool for planning successfully. AlphaGo demonstrated its capabilities about 5 years ago, and improvements have been steady ever since. Inspired by this, our work studies how human–computer interaction can benefit from similar approaches.

 We focus on adaptive systems that respond to user input and context, to make changes

 to the user interface.
 Adaptive interfaces have been on the receiving end of much criticism.
 Frequent and unexpected changes often cause annoyances and do not allow users to rely upon memory. As such, myopic algorithms do not typically take into account these costs or long-term
 benefits of changes. You could say that adaptive user interfaces haven’t really been winning so far!
 In our work, we aim to change this by developing a new method where interactive systems can
 use long-term planning to adapt their interfaces. Our method convincingly outperforms typical non-adaptive and adaptive baselines.

 We frame the problem of adaptation as a stochastic decision making problem. Here, the system must decide what changes it should make if any, by picking sequences

 of adaptations that can maximise utility. Given the noisy nature of user interactions, it should make these decisions while accounting
 for uncertainty. The problem can then be formalised as a Markov Decision Process
 where a state represents both the interface and the user and adaptations are actions that lead to different states.
 The goal of the system then is to maximise utility by picking an optimal policy for making adaptations. In a game like Chess or Go, a win or a loss is evident from the game state.

 But that is not the case during human–computer interaction. Estimating utility is much harder here.
 For one, as we interact with an adaptive interface, the benefits of an adaptation can not be immediately observed from interactions. Further, during our interactions, we also as users adapt and change over time.
 Also, while I might interact with the interface in a certain way, you may do it very differently.
 Let’s consider a simple case where a person comes across an adaptive menu such as this
 one.
 Through interactions, they learn and build up mental representations of the menu.
 So an adaptation that was beneficial initially might become quite harmful when made at a later time. To plan adaptations, we need a way to properly estimate the value of different states.
 This could be done by learning from interaction data, or through simulations with predictive models. In our work, we adopt existing models that are readily available for tasks such as pointing,
 typing, menu search, among others. Taking the example of menus, these models can be used to simulate how the user would
 search for an item; and how an adaptation might affect this search process.

 These predictive models can be used by a planning algorithm like Monte Carlo Tree Search to
 efficiently find adaptations. 
 estimates.
 To bring home the point, I’d like to show you a couple of examples of how our method adapts menus. In this simple case, the menu has 5 items that are adapted based on the user’s changing interests. As you might notice, through sequential adaptations, the average selection time goes down drastically.

 As a second example, here we see the result after three rounds of adaptations in a more complicated 15-item menu. While reducing selection time is important for menus, other usability factors such as
 facilitating skill acquisition or increasing enjoyment could be addressed too.
 Our work showcases how human–computer interaction can benefit from advances in artificial intelligence.
  takes into account how both the human and the computer might adapt over time.
 I’d like to conclude by saying that we are very excited to see how such methods are extended
 in the future to enhance our interactions in different domains. Thank you! ♫ Upbeat outro music ♫
