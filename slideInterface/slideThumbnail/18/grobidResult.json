{"authors": "Erin Beneteau; Julie A Kientz; Olivia K Richards; Jason Yip; Mingrui Zhang; Alexis Hiniker", "pub_date": "", "title": "Communication Breakdowns Between Families and Alexa", "abstract": "We investigate how families repair communication breakdowns with digital home assistants. We recruited 10 diverse families to use an Amazon Echo Dot in their homes for four weeks. All families had at least one child between four and 17 years old. Each family participated in pre-and post-deployment interviews. Their interactions with the Echo Dot (Alexa) were audio recorded throughout the study. We analyzed 59 communication breakdown interactions between family members and Alexa, framing our analysis with concepts from HCI and speech-language pathology. Our findings indicate that family members collaborate using discourse scaffolding (supportive communication guidance) and a variety of speech and language modifications in their attempts to repair communication breakdowns with Alexa. Alexa's responses also influence the repair strategies that families use. Designers can relieve the communication repair burden that primarily rests with families by increasing digital home assistants' abilities to collaborate together with users to repair communication breakdowns.\u2022 Human-centered computing \u2192 Human computer interaction (HCI); Collaborative interaction, Field studies, Empirical studies in HCI", "sections": [{"heading": "INTRODUCTION", "text": "The worlds of human-to-human communication and human-to-technology communication are quickly becoming blurred in everyday, family life. The increasing popularity of digital home assistants, like the Amazon Echo, and conversational assistants, like Siri, increase users' expectations of voice as an effective communication method with machines [23]. However, humans must work to adapt their communication patterns to the needs of the machines, rather than machines adapting to humans [19]. People shorten their sentences, use simplified language, and repeat themselves in attempts to be understood by voice interfaces [19,20,22,23,31]. As a result, users of voice interface technology become frustrated and can fail to learn the full capabilities of the technology, or abandon use altogether [10,23].\nDespite the difficulty with human-to-voice interface communication, the technology is becoming pervasive in family lives. Yarosh et. al found that 93% of the children they talked with at a state fair in Minnesota had used voice interface technology [43]. Digital home assistants, which utilize voice interfaces, are anticipated to be present in 55% of American households by the year 2022 [32]. Yet, the prevalence of the technology does not necessarily indicate the successful, ongoing use of the technology. True conversational capabilities have not yet been fully realized [33,34], and we want to better understand how human-technology \"conversations\" can be improved.\nIn our research, we blend two fields of study: humancomputer interaction (HCI) and speech-language pathology. HCI has a long history of research in how humans communicate with computers, robots, and other conversational agents [26,39]. Speech language pathology has a long history of research on human-to-human communication development, communication disorders, and remediation [14,35]. Drawing from these two fields, we aim to better understand the communication breakdowns and repair strategies used between families and digital home assistants, specifically, the Amazon Echo Dot (who we refer to as the conversational partner \"Alexa\").\nTo frame our study, we use the concepts of joint media engagement [40], conversational analysis [27], pragmatics [35], and discourse scaffolding [41]. Building on these concepts, we explore the communicative relationships between digital home assistants and families. Our specific research questions are: 1) What types of communication breakdowns occur? 2) How do families repair communication breakdowns with Alexa? 3) How does Alexa repair communication breakdowns with family members?\nWe gave Amazon Echo Dots to 10 economically and ethnically diverse families to use in their homes for four weeks. None of the families had previously owned a digital home assistant. We conducted pre-and postdeployment interviews with all 10 families in their homes, and we captured audio of natural, unscripted family interactions with Alexa. Based on an analysis of 59 conversational interactions, we discuss three types of responses from Alexa that signal communication breakdowns and a taxonomy of five strategies that family members used to repair breakdowns. At times, Alexa initiated collaborative communication repair opportunities with her communication partner, but currently, the brunt of communication repair work lies with the family. Designers could use the analysis of communication repair types to create relevant and helpful responses for digital home assistants to use during communication breakdowns. We conclude with design suggestions that can improve digital home assistants' facilitation of conversational repairs with families.", "n_publication_ref": 20, "n_figure_ref": 0}, {"heading": "RELATED WORK Human Communication and Communication Breakdowns", "text": "In the field of speech-language pathology, pragmatics incorporates the social aspects of communication, including turn taking, topic maintenance, socially appropriate speech and language use, and code switching [18,35]. Code switching involves the recognition of different communicative expectations for different communication partners and/or different communication environments [8]. The most explicit form of code switching is to switch languages to match the language of the communication partner, such as shifting from English to Spanish [13]. A subtle form of code-switching, in which the rules and use of language are dependent on the communication context, is demonstrated when a teenager uses a different conversational tone and different vocabulary when talking to friends than when talking to a parent. Pragmatics, and specifically code switching, requires some understanding and intentional thought behind communication interactions [17,35,36]. As such, linguistic code switching often begins around ages 4-5, when children begin intentionally talking in different ways to different people, in different settings [44].\nCommunication repair refers to the work of restoring shared understanding after conversational partners misunderstand each other. Essentially, the person who is talking needs to rephrase or say something differently because the person they were talking to did not understand what they were saying [25]. The ability to code switch can aid in conversational repair and can be thought of as the act of adjusting your speaking style to accommodate the listener [41]. These adjustments to speaking style can take many forms and are dependent on the communicator's language abilities. For example, children often use repetition as their initial repair strategy when presented with \"neutral\" clarification responses, such as \"huh,\" \"what,\" and \"I don't know\" [6,25]. Children ages nine and older might use contextual cues, such as defining terms, to repair a communication breakdown, whereas this can be more challenging for younger children [6]. Adults may engage in discourse scaffolding to assist children in expanding or adjusting their speech [41]. Discourse scaffolding is a mechanism to guide learning through communication strategies with the intention of gradually transferring skills and responsibility to the learner [38,41]. At an early communication stage, an example of discourse scaffolding is when a child says, \"cookie,\" and a parent responds with an expansion of the child's utterance: \"you want more cookies.\"\nDynamics between multiple communication partners, especially those involving young children, can be heavily influenced by the communicative development ages of the communication partners and the context of the communication interaction [14,18,21,24]. Our earlier example of discourse scaffolding was appropriate for a very young child, whereas the communication interaction between a teenager and parent would look very different. For example, a parent might use discourse scaffolding through questioning to lead the teen to expand on their own language. The parent might ask, \"What did you do after school?\" and the teen might reply, \"hung out with friends.\" The parent could then scaffold further elaboration with questions, such as, \"where did you and your friends hang out?\" While these examples highlight the nuances of communication interactions between family members of different ages and developmental stages, we find that the communication interaction can become even more complex when one of the communication partners is not human.", "n_publication_ref": 20, "n_figure_ref": 0}, {"heading": "Human-Computer Communication", "text": "The field of HCI has a well-established body of literature on how humans verbally communicate with computers, robots, and other devices. In 1987, Suchman framed acts of human-machine interaction as a dialog between communication partners [39]. From this perspective, the work of the designer is to enable human and machine collaboration towards a shared understanding through continuous acts of collaborative communication repair when breakdowns occur. Yet, despite this legacy, and improvements in human-computer communication techniques [2][3][4], research continues to demonstrate that humans adapt their communication styles and patterns to match the machine, both with robots [31,42] and computers [28,30], rather than the other way around. Humans shorten their sentences [20,31], use repetition [1], increase volume [5] and hyperarticulate [28] as repair strategies. These modification strategies are motivated by a desire to achieve successful communication with computers [5,30].", "n_publication_ref": 12, "n_figure_ref": 0}, {"heading": "Communication Breakdowns with Voice Interfaces", "text": "In recent years, the field of HCI has begun to examine human communication with conversational agents, such as Siri, and with digital home assistants, such as the Amazon Echo [10,23,34,37]. Despite the \"conversational\" interface with conversational agents, people are not yet able to talk to technology in the same way that they talk to other people [23,34]. Users of conversational assistants often need to shorten their queries to key words, since increased utterance length can increase the likelihood of speech recognition errors, both with conversational agents and with other humans [19,[22][23][24]. We also see young children using repetition as an initial conversational repair strategy when they are talking to a computer game [9]. With current systems, the burden of ensuring a successful communication interaction with a conversational agent continues to fall to the human in the conversation, with little support from the conversational agent itself [12,34].\nThe majority of research on communication breakdowns and repairs takes place in 1:1 interactions [19,20,22,24,25,31,43]. One of the few studies that investigates how multiple people work together to repair communication breakdowns with a conversational agent observed friends meeting in a caf\u00e9, using the conversational agents (such as Siri) on their phones [34]. The researchers used conversational analysis as their approach, based on the principle of analyzing naturally occurring interactions with technology from the user's point of view [27]. Their findings revealed that when a communication breakdown occurs with a conversational agent, multiple people attempt communication repairs, passing the phone from person to person. Our specific interest is how families repair communication breakdowns with digital home assistants in naturalistic use in their homes.\nWe can turn to literature on how technology is situated within family dynamics for reference, such as Takeuchi and Stevens documentation of \"Joint Media Engagement\" (JME) and the ways families make meaning around their technology experience [40]. Family members, particularly parents, use media as shared learning opportunities, scaffolding communication around the media experience [16,40]. Comparatively little work has examined children's and families' interactions with digital assistants. Yarosh and colleagues found that children struggled to formulate queries to a voice interface [43] and Cheng and colleagues define a taxonomy of communication repair strategies that preschoolers use when talking to a voice-driven game [9]. Porcheron et al. report on a study of five families using the Amazon Echo in their homes, and they describe how a family of two adults and two children take turns in attempting to repair a communication breakdown with their Amazon Echo [33]. The authors conclude that the device's responses to the communication breakdown are ineffective in supporting the participants in identifying the cause of the breakdown.\nIn this study, we expand the body of work on communication repair strategies with conversational agents and digital home assistants. We specifically explore how diverse families attempt to repair communication breakdowns with the conversational partner Alexa (their Echo Dot) through a close analysis of conversational interactions.", "n_publication_ref": 27, "n_figure_ref": 0}, {"heading": "METHOD", "text": "We conducted a four-week field study with 10 families, audio recording their everyday interactions with the Amazon Echo Dot (second generation).", "n_publication_ref": 0, "n_figure_ref": 0}, {"heading": "Participants", "text": "We recruited 10 diverse families to use the Echo Dot for a period of four weeks, intentionally recruiting families who represent a wide-spectrum of family life. Families selfidentified as never having owned a digital home assistant.\nFamilies also reported having a total household income at or below the median for the county in which the study was conducted. Families ranged from families of two to families of five (see Table 1). All families had at least one child between the ages of four and 17 living in the home. Two families were bilingual, in which all family members spoke both English and Spanish in their homes.", "n_publication_ref": 0, "n_figure_ref": 0}, {"heading": "Procedure", "text": "We collected audio data throughout the four-week period, using a custom-built audio sampling system designed to record interactions every time the trigger word \"Alexa\" was spoken. We also conducted pre-and post-deployment interviews with families in their homes at the start of the deployment period and at the conclusion of the four weeks. We compensated families with US$100 in gift cards for completing the study, and they were able to keep their Echo Dot after the conclusion of the study. The study was approved by our university's Institutional Review Board. ", "n_publication_ref": 0, "n_figure_ref": 0}, {"heading": "Audio Capture", "text": "To capture audio recordings of participants' interactions with the Echo Dot, we created an audio buffer system inspired by the open source code from Porcheron et al.\n[33]. The software captures audio when the trigger word \"Alexa\" is spoken; it saves one minute of audio prior to the trigger word, along with three additional minutes during and after the trigger word is spoken. It then pushes a total of four minutes of audio to a secure server.\nFor our study, we deployed the audio recording system on a Samsung tablet computer that families placed near the Echo Dot in each of their homes. We instructed families to keep the tablet plugged in and not to use the tablet for anything other than for the study's audio recording. The recording system also had both a \"record a thought\" button and a \"delete\" button available for families to leave explicit comments for the researchers or to delete the audio capture files, based on the desires of the participants.", "n_publication_ref": 0, "n_figure_ref": 0}, {"heading": "Analysis", "text": "We used an inductive process to analyze the audio capture conversational samples [7,11,29]. We began with memoing and open coding during the initial transcriptions of the audio capture files. Through memoing and open coding, we noticed an emerging theme related to communication breakdowns. We then began coding communication breakdowns from transcripts of each of the 10 families, developing and revising codes as we found additional examples of communication breakdowns, reviewing a total of 14.5 hours of audio capture. We continued this process until communication breakdown codes were stable and applicable to multiple families. Once codes were stable, we reviewed transcripts from each of the 10 families for communication breakdowns again. We included communication breakdowns from each family in our corpus of 59 communication breakdown interactions, systematically going through each individual family's transcript and pulling out communication breakdowns for each code (when present). If a family had multiple communication breakdowns for a particular code type, we reviewed the instances and chose no more than three instances of that code type for deeper analysis. For example, Family C had multiple instances of adjusting prosody; we chose three instances that we felt were most representative to be included in the corpus for deeper analysis.\nFor our final analysis on communication breakdowns and repairs, a total of 59 conversational interactions falling under the broad themes of communication breakdowns and repairs were deeply analyzed by two researchers. Communication breakdowns were defined as interactions between family members and Alexa which did not result in an appropriate response from Alexa to the human communication partner. We drew on the HCI conversational analysis approach to analyze family conversations set in natural environments, with a focus on the user's experiences. The use of conversational analysis in HCI aims to highlight opportunities for designers to improve interactions between humans and computers by detailing the structure of interactions from the user's perspective [27].\nThe first author, a speech-language pathologist (SLP), used speech-language constructs when analyzing communication breakdowns and repairs. Constructs are defined in our findings below. We also consulted a practicing SLP on the codes and themes related to family communication repair strategies. The practicing SLP validated the communication repair strategies identified and validated the repair types used in the conversational samples discussed in this paper. For additional validation, we consulted a second SLP, also a researcher, who validated the repair strategy definitions used.\nDuring our analysis, we discovered that family members were not the only communication partners to attempt communication repairs in conversations. Alexa also engaged in communication repair attempts, and therefore we have included an analysis of Alexa's communication repairs in the findings, in addition to family communication repairs.\nWe also want to explicitly state that in our findings and discussion, we refer to Alexa in a personified form. We do this for two reasons: 1) Alexa is a communication partner in the conversational interactions and is most easily identified by name and personal pronoun when discussing the complex interaction between multiple conversation partners. 2) We reflect our participant families' language describing Alexa, based on our interviews and audio capture.", "n_publication_ref": 4, "n_figure_ref": 0}, {"heading": "RESULTS", "text": "All 10 of our families experienced communication breakdowns with Alexa. To illustrate our findings, we discuss three distinct conversational samples from three different families in which we highlight the complex communication dynamics between multiple family members and Alexa. Before our discussion of these rich conversational samples, we provide an explanation of the constructs we use to describe the communication interactions between family members and Alexa (shown in Tables 2-4).\nOur families used a variety of specific speech and language repair strategies, which we categorize under the broader construct of \"communication repair types.\" Communication repair types are listed in Table 2, with quotes from our participant families used as examples.\nIn addition to specific repair strategies, we define a variety of discourse scaffolds between family members that occur during collaboration, adapted from the fields of education and speech-language pathology [38,41]. These scaffolds occur both between family members and between family members and Alexa. The discourse scaffolds are listed and defined in Table 3. Examples of discourse scaffolds are described when we discuss the three specific family communication breakdowns.  In this interaction, the son first asks his parents how to make popsicles, asking for consultation without the use of When he does not get the answer he is looking for, he changes communication partners and asks Alexa. At point, the family as a is now engaged with media, with Alexa as a consultant. We see throughout the interaction that all family members are listening to the conversational interactions with Alexa, as evidenced by the subsequent communication by family members related to Alexa's responses.\nWe know the son wants generalized information based on his initial word choice, \"what are popsicles made of.\" use of a plural and the lack of a specific type of popsicle indicates that he is interested in popsicles in general instead of a specific popsicle type.\nresponds on the correct topic-popsicles -but too specific of a response that deviates from the intended topic. the communication breakdown occurs, the son's mother actively engages in the interaction. However, her initial communication is with her son rather than with Alexa. She uses the breakdown as a learning opportunity to educate her son on improving his success in obtaining information from Alexa. The mother provides discourse in the form of direct instruction. She instructs her son, given her interpretation of the source of the breakdown with Alexa: his poor articulation in which Alexa misheard the word \"s'mores.\" She then provides further discourse scaffolding in the form of modeling by engaging with Alexa directly in a repair. The mother makes the first repair attempt by adjusting syntax of the question from, \"what are popsicles made to, \"how do you make a popsicle.\" As a result, the communication breakdown is somewhat repaired, and Alexa responds both on-topic and with specific relevant to the question. However, Alexa continues to provide information for a specific type of rather than a generalized recipe for any popsicle. At this point, Alexa assists her communication partners by refining her response and providing a summary of the popsicle recipe. Alexa then models two possible communication responses to communication partner: \"ask for more information\" or \"say next.\" By providing choices, Alexa is performing discourse scaffolding of her and promoting turn-taking in the communication interaction through a specific clarification response. The specific clarification further refines her response to more match the needs of her communication partner. The son, the original instigator of the communication interaction, resumes his role in the interaction with Alexa and responds to Alexa with \"next,\" one of the options that Alexa provided. However, it is clear that both the mother and father are engaged with the interaction and have had enough of Alexa's responses. The mother redirects the conversation by stopping Alexa.\nparents take on the roles of communication partners with their son. The family maintains the topic of but abandons Alexa as a communication for the remainder of the conversational topic. parents resume the discourse scaffolding that the mother earlier and lead their son to answering his own question.\n(Alexa): This might answer your question. There are five UN recognized countries in Eastern Asia: China, Japan, South Korea, Korea, and Mongolia. Did that answer your question? (Mother): Yes. (Alexa): Thanks for your feedback.\nThis interaction illustrates multiple types of communication repairs families our study used: adjustments, semantics adjustments, changes in volume, changes in prosody, and collaboration with family members. To the mother consults other family for information, and when they are not able to provide that information, the father suggests the family's go-to information resource: Google. By doing this, the father immediately provides discourse scaffolding and shifts the family's focus to include media. mother decides to try Alexa first, essentially shifting the family's media attention from Google as a resource to Alexa. The mother's question to Alexa closely follows the syntactical model suggested by the father for the Google search, with expansion to clarify the last key term \"Southeast Asian\" \"South.\" This form of question is essentially an either/or type of question, in which the requester provides two options and is looking for a response that one of those options. Alexa's response, instead, is a neutral response, I'm not sure,\" which does not provide her communication partner with any specific information on the cause of the communication breakdown.\ndaughter, originally asked as a primary information resource, actively takes part in the conversation with and takes a turn at repairing the communication breakdown. She uses her mother's query as a foundation for her interaction. daughter employs contraction by making a syntactical change: deleting the in the query and thus changing nature of the question to a yes/no question (\"Are Koreans Southeast Asian?\"). Alexa's response to this question is an extreme version of a neutral response, that of a beep and silence. The family conversation briefly comes to halt with this response from Alexa, causing a second, and perhaps more dramatic communication breakdown.\nAfter the brief silence, the mother encourages her to try again through direct instruction. At this point, both mother and daughter are actively engaged in jointly repairing the communication breakdown. The daughter employs repetition with increased volume in this repair attempt (the third total repair attempt for the family as a unit). Alexa responds with another neutral response, \"I'm not quite sure how to help you with that.\" this point, the mother resumes her original role in communicating with Alexa and attempts the fourth repair. She modifies her daughter's interaction through a combination of expansion and contraction. Utilizing a dramatic syntactic change, she breaks up her original either/or question into two closed ended questions, asking both \"who\" and \"what\" questions.\nBy now, we have seen the original question modified five times by three family members. Each time the is modified in relation to the prior family member's version of the question. Up to this point, Alexa has provided neutral responses, which resulted in the family collaborating to make a wide variety of repair Without any specific responses or actions from Alexa, the family did not have any signposts to guide their strategies. In response to the mother's two closed ended questions, Alexa acts on a misunderstanding. After the fourth repair attempt is unsuccessful, the daughter makes a noise of frustration and at this point the father actively the interaction with Alexa for the first time. His interaction indicates that he has been listening to the prior communication attempts between his family and Alexa but has waited to take his turn at communication repair. The father's communication repair employs another change, as well as increasing his volume. He shifts the question to a specific, closed-ended request: \"Please define East Asian countries.\" He also redirects Alexa from an off-topic response (countries in Eastern Europe) to the specific topic the family is interested in. All three family members collaborated to achieve a successful communication interaction with Alexa. Each family member listened to the interaction between Alexa and other family members and adjusted their interaction based on the prior interactions. At the end, after providing the desired information, Alexa instigates turn-taking with the family by asking them a question \"did that answer your question?\" mother, the initiator of the communication responds to Alexa's question. Alexa responds back to the mother with a statement that concludes the interaction on this topic.\nCommunication Breakdown 3: Family D final collaborative communication repair example is from one of our two bilingual families. We note that this final communication breakdown example is representative of two key themes found across our participant families: speech and language development impacting with Alexa (captured in multiple instances, but primarily with monolingual children) and Alexa struggling to understand bilingual individuals (also captured in multiple instances, but primarily with adults). Both of these themes were reinforced by family comments during our final interviews. The communication breakdown described below is the only that combined these two themes in one example.\nThis conversational interaction is from a family that speaks both and Spanish in their\nIn this example, the family has set up their Echo Dot for the first time and have just completed the guided setup through the Alexa app with the researchers in the\nThe mother encourages their 5-year-old to ask a question, but the 5-year-old has trouble with consistent production of the word \"Alexa.\" (Mother): It's A (pause) lexa (emphasis on the last two syllables) (Child): uh (slight pause) leh (pause) ska. Is it going to rain for a little or is it going to be sunny for a bit. (said quickly and quietly), (pause) or both. (no rising intonation at end to indicate a (pause and no response from Alexa) (Researcher): That was a good question but it might have been a little too long, too many questions I heard. (Mother): Let's see. (pause) Alexa, is it going to be rainy all day or sunny all day or . . . (recording cut off). (recording resumes child giggling) (Mother): Alexa, what did I ask you? (Alexa): Sorry, I'm not sure laughs) (Mother): Alexa, I asked if it was going to rain all day. (Alexa): not. Each of the next 7 days . has at most a chance of rain. (child laughs) engagement with Alexa is clear for the entirety of the communication interaction, evidenced by the communication partners' reactions to all interactions with Initially, the child's mother provides direct instruction to her child on improving the production of the word \"Alexa.\" found that many of the young children in our study struggled with the speech production necessary to make themselves consistently understood by Alexa. Developmentally, children at age 5 can be expected to have difficulty with the consistent production of some sounds, including the /l/ sound and /s/ which are both part of the word \"Alexa\" [44]. developing young bilingual children can be expected to make sound substitutions from one language another [15]. We see evidence of some of these speech patterns with the child in Family D our conversational sample described earlier.\nAnother theme we find in this example is the linguistic construction of the question the child asks Alexa: \"Is going to rain for a little bit or is it going to be sunny for a bit, or both?\" The syntax of the question is complex, asking Alexa three different questions about the weather into one. We also see that the child's use of language does not match Alexa's abilities. This is the first time this child has used a digital home assistant, and the is most likely unaware of the need to code-switch. Therefore, the researcher provides direct instruction and the child might have asked too many questions at The mother then modifies her child's question, by the syntax and semantics, to attempt her communication repair. However, Alexa does not respond.\nmother then makes another attempt at communication repair by asking Alexa, \"what did I ask Alexa provides a neutral clarification response. Joint engagement in the interaction is demonstrated by everyone laughing at Alexa's response.\nIn the communication repair, the mother modifies both the syntax and semantics of question to a contracted yes/no question. Alexa then appropriately to the question, which ends that communication interaction.", "n_publication_ref": 4, "n_figure_ref": 0}, {"heading": "Pragmatics: Code Switching with Alexa", "text": "Although we find that most family members in our study able to adapt communication interactions with Alexa, as evidenced through the multiple types of repair strategies used, not everyone was successful in this process. In particular, children under the age of 5 tended struggle more than older children and adults. For the parents of Family I report that one of their children (age 4) would walk up to the Echo Dot begin talking to Alexa without addressing her by name. The child would use long sentences and often change topic before Alexa responded. His parents felt that his communication with Alexa was similar to his communication with other people. The parents believed their son expected Alexa to respond to him like other people do, and they reported that he became frustrated she did not. In contrast, their older child (age 6) say Alexa's name and then pause before continuing communication interaction with her. It was not only young children that had a difficult time code switching. We find that Alexa did not code switch with family members to craft her communication interactions to the needs and abilities of the person she was addressing, as evidenced most clearly through she told. For example, the child in Family J asked Alexa to tell jokes the four-week deployment.\nresponded with a variety of jokes, such as: \"A man walks into a bar. Crank. It was a heavy metal bar.\" During our final interview with Family we asked the mother child if the jokes Alexa told were appropriate for the child (age 4). mother replied \"Yeah, there were a couple that [child's name] chuckled at but I don't think she (pause and mother directs question to child) 'do you know why the were funny? Did they make sense to you?'\" The child's response was \"No, I don't know why.\"\nAlexa's lack of code switching is not only evident with We find that Alexa is unable to code switch with multilingual users. For example, when the mother in D says, \"Alexa, play song by Marco Antonio Solis,\" the singer's name using Spanish phonological instead of an English phonetic version of the singer's name. Alexa's response is \"'Unbelieve,' by Andy this case, Alexa misheard or misunderstood the request because of her inability to code switch to that the requester was using the correct pronunciation for words in another language.\nWe can think of Alexa as being very literal with communication interactions, which implies a lack of understanding of the social nuances and uses of language, essentially, a deficit in pragmatic skills. An excellent example of Alexa's poor pragmatic skills is with Family A: Alexa did not understand that the pause in this case was in anticipation of continuing the request. In addition, Alexa did not understand that the semantic modification, from \"add\" to \"calculate\" was intended to provide a definition of the earlier request of the word \"add.\" Multiple meanings of words are a challenge for Alexa, and any communication partner that does not understand context of the communication interaction. Finally, failed to recognize the contextual cue that \"157\" was number and therefore the correct interpretation of \"add\" is to calculate. A final example of Alexa's inability to code switch is when the child in Family J asks Alexa to count to 10 in Spanish. Alexa responds by translating the word \"count\" from English to Spanish.", "n_publication_ref": 0, "n_figure_ref": 0}, {"heading": "DISCUSSION", "text": "Currently, the burden of repairing communication breakdowns with Alexa lies with family members. communication breakdowns with Alexa can take a great deal of effort on the part of multiple family and in some cases, might lead to abandonment. Our findings reinforce Suchman's suggestion from 1987: designers of machines should focus on designing for collaboration between the user and the machine to achieve mutual understanding [39]. To alleviate the burden on family members, and to increase chances of successful conversational repairs, we recommend that digital home assistants are designed with a focus on improving communication repair strategies.", "n_publication_ref": 1, "n_figure_ref": 0}, {"heading": "Digital Code Switching for Human Interaction", "text": "Understanding the communicative context and the communication partners involved in a conversation the field of pragmatics [35,36]. To improve repair strategies, knowledge of the and the communication partner is extremely helpful, allowing digital home assistants to artificially code switch as needed. We that Alexa (the Echo Dot) is a machine, and does not have pragmatic skills; however, it may be possible to build on the concept of code switching to design more appropriate interactions between digital home assistants and humans. Designers who are mindful of the varied skill levels and communication styles of family members can improve assistants' abilities to repair communication breakdowns. Younger children have difficulty with certain and sound combinations [44], and they tend to use repetition as an initial communication repair strategy [25]. If designers imbued voice assistants with the skills to identify that a communication partner is a young child, and therefore is likely to use repetition as a repair strategy and likely to have imprecise speech, a digital home can provide more specific communication feedback to collaborate on the communication repair. One way in which the specific feedback can be helpful is through the form of discourse scaffolding.", "n_publication_ref": 4, "n_figure_ref": 0}, {"heading": "Discourse Scaffolding and Specific Clarification Responses", "text": "Our findings demonstrate how parents use discourse to direct their child's communication interactions. With a designed ability to code-switch, Alexa can do the same, based on recognizing cues from the communication partner. Developing discourse scaffolds is an expansion of some basic functions that Alexa already has, such as performing specific clarification responses like, \"Do you mean 10:45 in the morning or the By developing the ability to code switch, Alexa apply directive discourse scaffolding a greater variety of communication interactions, based on her of the context and her communication partner. For example: Alexa could identify repetition and imprecise speech and respond with, \"I'm not sure you're asking. Can you tell me just the key word of what you want?\"\nOther work in the area of conversational interfaces has made similar suggestions for conversational agents to cues and prompts to collaborate with their human partners [9, 12,19,34,43]. Here, we further suggest that the constructs of discourse scaffolding and switching could be productively applied to the design of digital assistants. Discourse scaffolding can be applied any conversational partner (adult or child), and through code switching, customized to provide the level of support that is appropriate for the specific conversational partner. Our close analysis of conversational breakdowns and repairs with family members provides an initial guide for developers to design conversational strategies which incorporate code switching and discourse scaffolding.\nWe realize that the application of code switching may inadvertently create new miscommunications between Alexa and her communication partners. Alexa might an adult using repetition and talking while chewing gum as following the same patterns as a young child. However, the use of specific responses provides more signposts for communication repairs than neutral clarification responses. If Alexa makes a mistake, it is easier for her human communication partner to the cause and make the repair with specific Ideally, the responses from her human communication partner allow Alexa to learn her communication partner's speech patterns over time, making code switching easier, and increasing the accuracy of communication responses.", "n_publication_ref": 4, "n_figure_ref": 0}, {"heading": "Promoting Family Engagement and Communication", "text": "Based on our findings, we see how the concept of joint engagement [40] is useful for designers to consider creating applications and skills for digital home assistants. Due to the conversational nature of the interaction, other people in the immediate environment listen to and engage in communication with digital home assistants when there is a communication breakdown, at home and in other social settings [33,34]. Designers of digital home assistants can capitalize on this knowledge and engage families in positive, joint experiences, even when only one family member initially engages with the digital home assistant. We saw from our participant families that some family members did not engage immediately with Alexa until other family members had engaged in multiple interaction For example, when designing an Alexa skill for multiple players, such as a game or competition, family members might be encouraged to join in midway through:\nthere anyone else who can jump in and help?\" Utilizing the concept of joint media engagement, digital home assistants can simultaneously build their own pragmatic skills while assisting family members with their own conversational skills. If the digital home assistant is transparent about the nature of the communication breakdown, it can increase family members' own of their communication skills. In this way, the digital home assistant can model meta-pragmatic skills, in which people talk about their own social use of language and their understanding of the social use of language [41]. Digital home assistants have the potential to become facilitation tools for communication both between family members and between family members and the digital home assistant.\nBased on our analysis of diverse families' communication breakdowns and repairs with Alexa, we find many opportunities to support the growth of Alexa's skills. We particularly want to emphasize the potential for digital home assistants to assist their human communication partners in repairing communication breakdowns. Our interactions with technology have radically changed since Suchman's work in 1987, however, the hurdle of overcoming communication breakdowns remains the same [39]. Voice interfaces provide a unique opportunity for technology to on the burden of developing a shared understanding with their human communication partners.\nThe corpus of communication interactions analyzed for this study is a subset of the total communication captured and likely excludes additional examples of communication breakdowns and repairs. Our are also limited in that some families expressed an awareness of needing to \"use\" the Echo Dot during the study, and this may have perpetuated their attempts to repair communication breakdowns with Alexa. To mitigate that effect, our corpus includes communication segments that occurred throughout the fourweek study period. Our sample is also limited to 10 families in one area of the United States. Future work remains to conduct a larger scale analysis of families in regions with a broader range of language and differences.", "n_publication_ref": 5, "n_figure_ref": 0}, {"heading": "CONCLUSION", "text": "burden of repairing communication breakdowns humans and technology continues to rest with humans. Our findings highlight how families collaborate in a variety of ways to repair communication breakdowns with digital assistants, often requiring multiple attempts with more than one family member trying to successfully communicate with Alexa (the conversational name used with the Echo Dot). While makes some attempts to repair communication breakdowns through specific clarification responses, neutral clarification responses are far more common, which do not aid in helping the human communication partner repair the breakdown.\nWe turn back to 1987 and Suchman's guidance that designers focus on improving how technology can promote shared understanding with their human communication partners. Rather than trying to anticipate a user's needs, the digital home assistant can promote collaboration through improvements in communication breakdowns. To this end, we that designers incorporate specific processes which promote the artificial pragmatic skills of digital home assistants. Improving technology's ability to identify human communication partners and to provide specific clarification responses will ultimately improve the ability for humans and machines to collaborate towards understanding in their conversational interactions.", "n_publication_ref": 0, "n_figure_ref": 0}, {"heading": "ACKNOWLEDGMENTS", "text": "research was funded, in part, by a grant from Mozilla. We also want to acknowledge our appreciation of the speechlanguage pathologists who we consulted for validity checks of our coding for communication repair types: Teresa Fleck, a practicing SLP of 20 years, and Victoria Lai, an SLP and researcher. We also appreciate the transcription and administration support of Bella Yini Guan, Leanne Liu, Heung, Ashley Boone and Kate Yen. Finally, we sincerely thank the participant families, without whom this research would not be possible.", "n_publication_ref": 0, "n_figure_ref": 0}], "references": [{"title": "Interaction with Agent in a Spoken Dialogue System", "journal": "", "year": "2018-09-13", "authors": "Linda Bell;  Gustafson"}, {"title": "Modeling the cost of misunderstanding errors in the CMU Communicator dialog system", "journal": "", "year": "2001", "authors": "D Bohus; A I Rudnicky"}, {"title": "Open-world dialog: Challenges, directions, and prototype", "journal": "", "year": "2009", "authors": "Dan Bohus; Eric Horvitz"}, {"title": "Linguistic alignment between people and computers", "journal": "", "year": "2010-09", "authors": "Dan Bohus; Eric Horvitz; ; Branigan; Martin J Pickering; Jamie Pearson; Janet F Mclean"}, {"title": "Development of conversational repair strategies in response to requests for clarification", "journal": "J. Speech Hear. Res", "year": "1986-03", "authors": "Bonnie Brinton; Martin Fujiki; Diane Frome Loeb; Erika Winkler"}, {"title": "The SAGE handbook of grounded London", "journal": "SAGE Publications", "year": "2007", "authors": "Antony Bryant; Kathy Charmaz"}, {"title": "Codes and Contexts: Exploring Linguistic, Cultural, and Social Intelligence", "journal": "ASHA Lead", "year": "2007-05", "authors": "Li-Rong Lilly Cheng"}, {"title": "Why Doesn'T It Work?: Voice-driven Interfaces and Young Children's Repair Strategies", "journal": "", "year": "2018", "authors": "Yi Cheng; Kate Yen; Yeqi Chen; Sijin Chen; Alexis Hiniker"}, {"title": "What Can I Help You with?\": Infrequent Users' Experiences of Intelligent Personal Assistants", "journal": "", "year": "2017", "authors": "R Benjamin; Nadia Cowan; David Pantidi; Kellie Coyle; Peter Sara Morrissey; David Al-Shehri; Natasha Earley;  Bandeira"}, {"title": "inquiry & research design: choosing among five approaches", "journal": "", "year": "2018", "authors": "John W Creswell"}, {"title": "Google is It OK if I Eat You?\": Initial Explorations in Child-Agent Interaction", "journal": "", "year": "2017", "authors": "Stefania Druga; Randi Williams; Cynthia Breazeal; Mitchel Resnick"}, {"title": "Code-Switching in Highly Proficient Spanish/English Bilingual Adults: Impact on Masked Word Recognition", "journal": "J. Speech Lang. Hear", "year": "2018", "authors": "Paula B Garc\u00eda; Lori Leibold; Emily Buss; Lauren Calandruccio; Barbara "}, {"title": "Requests and responses in children's speech*", "journal": "J. Child Lang", "year": "1975-04", "authors": "Catherine Garvey"}, {"title": "", "journal": "English Speech Sound Development in Preschool-Children From Bilingual English-Spanish Environments. Lang. Speech Hear. Serv. Sch", "year": "2008-07", "authors": "Christina E Gildersleeve-Neumann; Ellen S Kester; Barbara L Davis; D Pe\u00f1a"}, {"title": "Plan & Play: Supporting Intentional Media Use in Early Childhood", "journal": "", "year": "2017", "authors": "Alexis Hiniker; Bongshin Lee; Kiley Sobel; Eun Kyoung Choe"}, {"title": "Pragmatic Language Assessment: A Pragmatics-As-Social Practice Model", "journal": "Top. Lang. Disord", "year": "2007-04", "authors": "Yvette D Hyter"}, {"title": "Normal Language Acquisition", "journal": "Allyn & Bacon, Incorporated", "year": "1990", "authors": "Sharon L James"}, {"title": "How Do Users Respond to Voice Input Errors?: Lexical and Phonetic Query Reformulation in Voice Search", "journal": "", "year": "2013", "authors": "Jiepu Jiang; Jeng ; Daqing He"}, {"title": "Dialogue with machines", "journal": "Cognition", "year": "1988-10", "authors": "Alan Kennedy; Alan Wilkes; Leona Elder; Wayne S Murray"}, {"title": "Language Disorders and Language Development", "journal": "Pearson", "year": "1988", "authors": "Margaret Lahey"}, {"title": "Try something else!\" -When users change their discursive behavior in human-robot interaction", "journal": "IEEE International Conference on Robotics and Automation", "year": "2008", "authors": "M Lohse; K J B Wrede; G Sagerer"}, {"title": "Having a Really Bad PA\": The Gulf Between User Expectation and Experience of Conversational Agents", "journal": "", "year": "2016", "authors": "Ewa Luger; Abigail Sellen"}, {"title": "Communication in Normal and Language Learning-Disabled Children's Conversation and Narration", "journal": "J. Speech Hear. Disord", "year": "1988", "authors": "G Barbara; Robin S Maclachlan;  Chapman"}, {"title": "The Use of Repair Strategies by Children With and Without Hearing Impairment", "journal": "Speech Hear. Serv. Sch", "year": "2002-04", "authors": "Tova Most"}, {"title": "Human Values and the Design of Computer Technology", "journal": "", "year": "1997-08-31", "authors": "Clifford I Nass; Youngme Moon; John Morkes; Eun-Young Kim; B J Fogg"}, {"title": "Informing HCI design through analysis", "journal": "Int. J. Man-Mach. Stud", "year": "1991-08", "authors": "A Norman; P J Thomas"}, {"title": "Linguistic during spoken and multimodal error resolution", "journal": "Lang. Speech", "year": "1998", "authors": "Sharon Oviatt; Jon Bernard; Gina-Anne Levow"}, {"title": "Qualitative research & evaluation methods: theory and practice", "journal": "SAGE Publications, Inc", "year": "2015", "authors": " Michael Quinn Patton"}, {"title": "Adaptive Language Behavior in HCI: How Expectations and Beliefs About a System Affect Users' Word Choice", "journal": "", "year": "2006", "authors": "Jamie Pearson; Jiang Hu; Holly P Branigan; Martin J Pickering; Clifford I "}, {"title": "Why That Nao?: How Humans Adapt to Conventional Humanoid Robot in Taking Turns-at-Talk", "journal": "", "year": "2016", "authors": "R M Hannah; Mathias Pelikan;  Broth"}, {"title": "Voice-enabled smart speakers to reach 55% U.S. households by 2022, says report. TechCrunch", "journal": "", "year": "2018-09-05", "authors": "Sarah Perez"}, {"title": "Do Animals Accents?\": Talking with Agents in Multi-Party Conversation. In of the 2017 ACM Conference on Computer Supported Work and Social Computing (CSCW '17)", "journal": "", "year": "2017", "authors": "Martin Porcheron; Joel E Fischer; Sarah Sharples"}, {"title": "Pragmatics as Social Competence", "journal": "J. Speech Hear", "year": "1982-05", "authors": "Carol A Prutting"}, {"title": "", "journal": "Parsing Pragmatics. ASHA Lead", "year": "2012-10", "authors": "Kenyatta O Rivers; Yvette D Hyter; Glenda Dejarnette"}, {"title": "Hey Alexa, What's Up?\": A Mixed-Methods Studies of In-Home Conversational Agent Usage", "journal": "", "year": "2018", "authors": "Alex Sciuto; Arnita Saini; Jodi Forlizzi; Jason I Hong"}, {"title": "Unpacking\" Scaffolding: Identifying Discourse and Strategies that Support Learning", "journal": "Lang. Educ", "year": "2006-05", "authors": "Tina Sharpe"}, {"title": "Plans and situated actions: The problem of humanmachine communication", "journal": "Cambridge university press", "year": "1987", "authors": "A Lucy;  Suchman"}, {"title": "The new coviewing: Designing for learning through joint media engagement", "journal": "", "year": "2011", "authors": "Lori Takeuchi;  Stevens"}, {"title": "Coordination of verbal and non-verbal actions in human-robot interaction at museums and exhibitions", "journal": "Pearson", "year": "1994", "authors": "Geraldine P Wallach; Katharine G Butler"}, {"title": "Children Asking Speech Interface Reformulations and Personification Preferences", "journal": "", "year": "2018", "authors": "Svetlana Yarosh; Stryker Thompson; Kathleen Watson; Alice Chase; A J Ashwin Ye Yuan;  Bernheim Brush"}, {"title": "Four to Five Years Old", "journal": "American Speech-Language-Hearing Association", "year": "2018-08-20", "authors": ""}], "figures": [{"figure_label": "", "figure_type": "", "figure_id": "fig_0", "figure_caption": "(Mother): Alexa, add 157 (slight pause) (Alexa): I added 157 to your shopping list. (Mother): Alexa, calculate 157 plus 50 (pause) (Alexa): Sorry, I didn't catch that.", "figure_data": ""}, {"figure_label": "1", "figure_type": "table", "figure_id": "tab_0", "figure_caption": "Total family members, ages, and ethnicity of participant families.", "figure_data": "FamilyN AdultAdultsChildEthnicityIDNageagesrangesA4341-68+13AsianB4318-5512White/AsianC2141-559WhiteD4226-553, 5HispanicE5326-674, 8White"}, {"figure_label": "2", "figure_type": "table", "figure_id": "tab_1", "figure_caption": "Speech and language repair strategies used by family members.Our final construct is that of Alexa's responses and how they signal communication breakdowns. We encountered three types of responses from Alexa that indicate a communication breakdown. Examples from our audio capture of Alexa's responses are listed in Table4.", "figure_data": "Repair TypeDefinitionExampleProsodicAdjustments to\"Alexa . . what is . . thechangesthe rhythm or. . temperature?\" [eachcadence ofindividual wordspeech, includingpronounced slowlypausing and theand clearly instead ofrate of speechin a conversationalmanner]-Family COverarticul-Exaggerating\"Alexa, play 'Make itationsounds, alsoRain' by Dack steN\"referred to as[emphasis andhyperarticul-prolongation of finalation [22]consonant]-Family CSemanticModifying the\"Alexa, play little kidadjustmentsmeaning of amusic.\"andword or sentence,(Alexa): I couldn't findmodificationincludingany little kid songs.providing \"cues,\"\"Alexa, play kidssuch as definingsongs.\"-Family Ga word [6]IncreasedThe speaker\"Alexa stop.\"volumeraises their voice\"Alexa stop!\" [louder] -specifically forFamily Dthe interactionwith Alexa"}, {"figure_label": "3", "figure_type": "table", "figure_id": "tab_2", "figure_caption": "Discourse scaffolds families used to support one another in reformulating their communication with Alexa.", "figure_data": "Discourse ScaffoldDirect instructionTelling a family member what theysay or why something hasProducing an utterance to demonstratethe desired responseRedirectionRefocusing the on a desiredtopicExpansionAdding on to something said bysomeone elseContractionShortening something that has been saidConsultingFamily members asking others forassistance or information"}, {"figure_label": "4", "figure_type": "table", "figure_id": "tab_3", "figure_caption": "Signals from Alexa that a communication breakdown has occurred. first communication breakdown occurs in Family E, who are talking while music is playing on their Echo Dot. topic of conversation is about popsicles, a ice treat. The son (age 8) initiates with Alexa. Alexa responds by acting on a misunderstanding. The mother collaborates with her son in repairing the communication breakdown, to which Alexa responds with clarification responses. The family ultimately carries on the conversational topic without Alexa.", "figure_data": "Response typeDefinitionExampleActing onPerforming an\"Alexa, whatMisunderstandingaction orwe do this(AoM)providing aresponse based onAlexa respondsmisheard orwith a definitionmisunderstoodof \"this night.\"inputNeutralProviding an\"Sorry, I don'tClarificationindication that theknow that.\"Response (NR)communication\"Sorry, I'm notpartner'ssure.\"interaction wasnot quite sureunclearhow to help youthat.\""}], "doi": "10.1145/3290605.3300473"}