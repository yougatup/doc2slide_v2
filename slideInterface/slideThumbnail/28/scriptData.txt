
 I'm not really supposed to be here. It's supposed to be Pranathi, my student, giving this talk, but she had visa issues, so instead, you get me. This work is done with a former student of mine, Adil Yalcin, as well as a colleague at SAS Institute, Xan Gregg. And to give you some background at what we're looking at,
 there are many examples of ordered or sorted lists where you have items and values. So think of, for example, the ranking of happiness for different countries in the world, the scores of your favorite teams in the league, maybe the cost for tuition at universities and so on. So ordered lists are common, and a common way
 to visualize these, if we take an example of countries, is just a scrolled barchart, right? So you have items, and you have the bars, the width of the horizontal bars here, showing values. Of course, with a representation like this, if I have a longer list than fits the screen, I'll have to scroll. That's the part of the word.
 So we call these ranked lists in this paper.
 where we have associated data values. So this is clearly a prevalent type of data that shows up, and the representations we're talking about often are part of visualization dashboards.
 Of course I mentioned, if you have a long list, you're gonna have to do scrolling, and scrolling takes time. You'd have to do interaction, and that will take time. So in recent years, a couple of authors and designers,
 practitioners have proposed alternative visualizations that try to use the space more efficiently. So lemme swap over and show you a few of these.
 It's just a web-based library for visualizing these things.
 A common way to visualize this, maybe just because it's one of those defaults in Tableau, is treemaps.
 are designed, really, for visualizing hierarchies, so trees. And a list like this is certainly not a hierarchy. It's a flat list. But it turns out they can, it often happens in practice, either this or something like it, like a bubble chart where you have the area of visual marks showing the size of the value. And as a visualization designers, this would always used to make me cringe a bit, because we know from experience in graphical perception that assessing length, as length of a bar, is more accurate than assessing area.
 So this is a wrapped bar. The idea is that you use the horizontal space of the charts more efficiently so that you can eliminate scrolling, and instead you introduce these columns. So in this case, we have, what is it? Five columns? That each show the bigger values from left to right, but of course that means you can see everything on the screen at one point. You don't have to scroll. The downside is that you lose some resolution now, because each of these columns get less horizontal space to fit in, so minute differences between an individual countries here might not be as obvious as they were in the other representation. So a couple years ago, my student Adil, who I mentioned one of the co-authors of this work, he proposed a technique that he called piled bars, that was inspired by this. But instead of using, well, we still segment the bar into pieces, but instead of using columns, we use the same baseline.
 So you see here that the bars now get stacked on top of each other, or piled on top of each other. So they all have the same baseline.
 that Steven Few, independently working with a designer called Daniel Zvinca proposed, and you see that the representation is very similar to our piled bars, but instead of using bars, we use dots. A little like Mike was mentioning in the questions of the previous talk here. So the dots now show the top values. So they don't show the entire bar. Which means you don't have overlap. You don't have over-plotting to the same degree. And then 2017, Xan, who's one of our co-authors, proposed the poster at InfoVis that he called packed bars, and the idea here is a little different. We still use horizontal space so
 that we can squeeze all the items on the screen at the same time, but they use the rectangle packing, where only the biggest items are shown with a common origin, though. So the blue ones. And then additional items are packed in a greeting algorithm where they fit. All right, so those are six representations, and
 which one is the best one? That was the starting point for this project.
 So to answer that question, we ran a crowdsourced graphical perception study where we wanted to compare accuracy and completion time for these six techniques, for three different representative tasks. And I'll talk about the tasks in a moment. And of course, the size of these lists that we're visualizing may also have an impact, so we looked at three different data sizes. 75, 150, and 300 items. And I'm gonna mention that at the end as a limitation. These are not huge lists. So at the same time, typical dashboards don't have lists of thousands or hundreds of thousands of items for the type of categorical data we're dealing with. But still, this is, are still small lists, so I'm not gonna try to argue that this is a big dataset by any mean. Every participant saw ten repetitions, and you'll note here, the BP means between participants, and WP means within participants. Because these are crowdsourced studies, we can only keep crowd workers for a limited amount of time, and we didn't wanna train them on more than one technique and one task at any point in time. So every person saw 10 repetitions of one visualization for one task. So we planned to have 10 participants for each combination of technique and task. Because of some software concerns, we ran the study, and some login concerns, we ended up with 222 participants and 6684 trials.
 So what about the tasks? Well, we wanted a good spread of tasks that capture the type of things you might do with a ranked list visualization like this one. So the first task is a one-item type of task that deals with a single item. So we called it a rank task. Basically, the goal, you see the interface here that people would see through their web browsers, of marking an item and then asking the participant to rank what order, out of one to 75 items, is this particular item. So that was one item.
 So in this case, comparison. So given two items that are marked using a circle and a star, signify which one is smaller, and then estimate the size of the smaller one to the bigger one. And after a cardinality of one-two,
 the third one was more of an overview task that involved all of the items. The goal here was to correctorize the distribution by assessing the average of all the data that's in the view. All right, so we ran our study,
 and it's worth noting first, perhaps, that we have looked at this problem before. In 2016, we started a study like this
 Anyway, so here's the results. I'm not gonna bore you with all the details. You can take a look at the paper for those. These are confidence intervals, 95% ones, for broken down by the task. Those are the three columns. And then you see technique per data size. So lemme just give you a summary.
 We found, in general, that wrapped bars had the best overall error, this is error, so how far off you were from the correct answer, had the best overall performance, even if scrolled bars was probably the most accurate one. Zvinca Plots did pretty poorly, except for the mean task, assessing the mean of the dataset. And I'll talk about that in a moment. Treemaps did surprising well. And again, this just goes against some of the wisdom of the field, knowing that area is harder to assess than length.
 Here's the completion time data. Again, I'll give you the highlights.
 Not surprisingly, scrolling bars were the slowest in all the examples, basically. And that's because there's interaction involved. You have to scroll up and down to see all the data values. The mean task was the most time consuming one. Trying to assess the entire data set, that's not too surprising that that takes time. Again, and yeah, so these are all, more or less, expected findings.
 So what does this all mean? Summarizing our implications, not surprisingly,
 as I already said, scrolled barcharts were accurate, perhaps, because they're familiar, but they were also slow.
 and not being the least accurate one. Actually, it was pretty good all around.
 Although, wrapped bars sort of outperformed the others in terms of all-round performance. So it's probably the visualization I should suggest. It has a good mix of familiarity as well as performance.
 Zvinca plots, I mentioned, did particularly well for the mean task, which is assessing an entire dataset. And that is, perhaps, because it really becomes more of a scatterplot. You're trying to find the centroid of the points, rather than bars, so that gets harder, whereas the centroid of the points,
 Limitations, we have a few.
 We are not looking at big datasets. These are small things that we typically see in dashboards, but certainly something to look at in the future. And Daniel Zvinca, who's the designer of the Zvinca Plots, we've been in touch with him. He's a little disappointed that we didn't look at very large visualizations. And it's also could be argued that, perhaps, treemaps would do better if you have very large datasets, because you're doing a space-filling representation that efficiently uses all of available space.
 We also did low-level tasks, perhaps not those that you might, we think that they are building blocks to higher-level tasks, but we haven't tested that.
 And also, in talking to Steven Few, he was disappointed that we didn't involve data visualization experts, and just crowd workers, and perhaps some of these representations would have different performance if the people that were using them were actual experts.

 and assumed the start of the gradient was the start of the baseline. Is that something that you could detect in your experiment results? And if so, how often did that happen? - So, in the experiments, there was no interaction. So you couldn't, what I can do now,
 especially making it such that, at least on the far left, there's an obvious ordering for the ranking, and maybe it breaks down a little on the right-hand side. - Absolutely, yeah. - [Host] So is there maybe another algorithm that would make this even better? - Yeah, we talk about it briefly in the paper, and it's also interesting, I didn't note it in the presentation. That's one place where our new study differed from our old study. So we show that treemaps were not as bad as we thought. In the old study, they got poorer results, and that is because we used a different layout algorithm. So this is a squarified treemap layout algorithm, and as you note, there is that deterministic sum. You know, you get an ordering from area, large to small. So that will have an impact, effect. And what would be interesting to see if there are other layout algorithms that would make it even more clear. - [Host] Cool. So we have time for one more question while the speakers switch.
 there's an obvious ordering for the ranking, and maybe it breaks down a little on the right-hand side. - Absolutely, yeah. - [Host] So is there maybe another algorithm that would make this even better? - Yeah, we talk about it briefly in the paper, and it's also interesting, I didn't note it in the presentation. That's one place where our new study differed from our old study. So we show that treemaps were not as bad as we thought. In the old study, they got poorer results, and that is because we used a different layout algorithm. So this is a squarified treemap layout algorithm, and as you note, there is that deterministic sum. You know, you get an ordering from area, large to small. So that will have an impact, effect. And what would be interesting to see if there are other layout algorithms that would make it even more clear. - [Host] Cool. So we have time for one more question while the speakers switch.
 I'm sorry, hi, I'm Mike Newardheisen, I'm with Microsoft. Looking at your treemap, it seems like the data is fairly closely in the same neighborhood, like rough magnitude. But if you had a different kind of disparity in data, like maybe more a logarithmic scale, how would you think that might affect your results? - Yeah, so if you take a look at the website, there's an option, so you can change the skew data, and I've been unplugged so I can't show you. But I think the problem with treemaps is that the items get small, the labels disappear, so that, we wanted to avoid that in our study, because then you couldn't read the items. So we only looked at uniform distributions where you have that effect, as you know. I think treemaps are gonna do better for that type of situation.
 That would be my gut feeling. - [Host] Great, thanks again. (audience applauding)
