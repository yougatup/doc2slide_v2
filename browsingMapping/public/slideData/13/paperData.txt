• Human-centered computing → Visualization theory, concepts and paradigms; Visualization techniques.
Virtual/Augmented Reality, Meta-Analysis/Literature Survey
Kurtis Danyluk, Barrett Ens, Bernhard Jenny, and Wesley Willett. 2021. A Design Space Exploration of Worlds in Miniature. In CHI Conference on Human Factors in Computing Systems (CHI ’21), May 8–13, 2021, Yokohama, Japan. ACM, New York, NY, USA, 15 pages. https://doi.org/10.1145/3411764. 3445098
As extended reality (XR) devices become more portable and powerful there is an opportunity for applications that have been previously limited to static desktop and laboratory spaces to move out into the world. Worlds-in-Miniature (WiMs) are one such technique that have been used for decades in the context of virtual reality (VR) as a tool for navigation and object manipulation, but which also have many promising applications in systems across the spectrum of virtuality [28]. As XR devices become less tethered to desktop computers, so too do the potential uses for WiMs.
There is not only renewed interest, but there is also a great potential for WiMs given the appearance of AR-capable chip sets on ubiquitous handheld devices — already being used in applications like Google Maps1. Location-based games like Pokemon Go could also beneft from minimap WiMs, and outdoor hobbies like hiking can take advantage of the 3D nature of WiMs to improve viewer perception [25]. In architecture, VR walkthroughs are becoming more common [36] and WiMs have a long history as a tool for navigating virtual buildings. Now is a time to revisit prior work and learn from it, providing a more structured view of WiM design which can inform future systems.
To better understand the design and use of WiMs, we collected and analysed 25 examples of WiMs from the research literature to derive a design space based on seven design dimensions: size-scopescale, abstraction, geometry, reference frame, links, multiples, and virtuality. We explain these dimensions in detail, and discuss how changes to individual dimensions infuence the fnal uses of a WiM.
Using these design dimensions, we compare and contrast different approaches for creating WiMs and identify the importance of specifc design choices. Based on this comparison we identify opportunities not covered by prior systems and use these to propose novel WiM designs (Figure 1). For designers, our framework highlights alternatives to traditional WiM archetypes and surfaces a variety of design choices and trade-ofs. Meanwhile, for researchers, our collection of related work can help facilitate new discussions about the value of WiMs and stimulate new designs.
This paper makes several contributions. First, we propose an expanded defnition of WiMs that better captures their presence across the XR spectrum. Second, we identify a set of design dimensions that help describe and diferentiate the forms and features of a diverse range of WiMs. Third, we use our design space to identify gaps in the existing literature and propose example systems that illustrate potential future applications of WiMs.
Scale models have served as visualisation tools in many contexts throughout history because they make it possible to view, inspect, and modify environments from perspectives and scales unattainable by human viewers. For example, the Musée des Plans-Reliefs 2 in Paris, houses dozens of scale relief models, built in the feld to give Louis XIV and his military planners a clearer perspective of French cities and fortifcations. In architecture there is a long history of using scale models to better explore, situate, and communicate about the forms of future buildings [20]. For example, the architect
1https://arvr.google.com/ar/ 2http://www.museedesplansreliefs.culture.fr/
Antoni Gaudí3 famously made 1:25 and 1:10 scale plaster models of his designs to better understand their form4. As such, it comes as little surprise that scale models have also made their way into virtual environments, where their construction is signifcantly easier.
Worlds-in-Miniature were frst introduced in the context of VR by Stoakley et al. [44] who defned them as:
immersive head tracked display with a hand-held miniature copy of the virtual environment. In addition to the frst-person perspective ofered by a virtual reality system, a World in Miniature ofers a second dynamic viewport onto the virtual environment. Objects may be directly manipulated either through the immersive viewport or through the three-dimensional viewport ofered by the WIM.
This represents the intended use of the original system as an interaction metaphor designed for object manipulation, but it limits WiMs to VR and object manipulation. More recently Cofey et al. [11] defned WiMs as such:
The core WiM concept is to provide a small (e.g. handheld) model of the virtual environment that can act as both a map and an interaction space as the user explores the large-scale environment — essentially a world within a world.
This defnition acknowledges that WiMs are used as a generic interaction space, and more than just an object manipulation tool, but fails to acknowledge that WiMs feature at a variety of sizes, and in mediums beyond just VR. To capture these systems we propose a more inclusive defnition:
interaction or virtual feedback — an interactive world within a world.
This defnition encompasses WiMs’ use as a tool for object manipulation in VR [44] as well as examples that transcend object manipulation in VR and include interactions, such as navigation and IoT control. This includes example WiMs created by researchers like Kalkusch et al. [22], who created an augmented reality (AR) WiM that sat on the viewer’s wrist, like a watch, and was used for indoor path fnding. Mulloni et al.[29], meanwhile, used AR miniatures to support indoor navigation by giving turn-by-turn navigation instructions at key “info” points. Seo et al. [40] combined both physical models and handheld AR to create WiMs that functioned as a smart home controller. In these cases the WiM is no longer just an object manipulation technique, the replica has instead been turned into an interaction space where operations on the replica are refected in the environment they represent, and changes to the outside environment are refected in the WiM. Some of this has made its way to commercial applications — in 2019 Google added AR support to their Maps application and featured many of the interactions explored by Mulloni et al. [29], using a
3https://sagradafamilia.org/en/antoni-gaudi 4https://blog.sagradafamilia.org/en/the-trades/model-makers/
WiM to support navigation between points of interest and placing AR navigation cues into the environment at these locations.
Beyond creating WiMs for diferent applications and in new spaces, there has also been a broader efort to improving the replica component of WiMs. To name just a few examples, Wingrave et al. [49] created a WiM that could be dynamically scrolled and scaled to better support large scale environments. Trueba, Andujar, and Argelaguet [47] automatically reduced occlusion in WiMs by dynamically exploding buildings [1]. Bonsch, Freitag, and Kuhlen [6] explore the automatic generation of WiMs in realistic environments.
As WiMs often function as 3D maps themselves, their designs have also drawn considerable inspiration from the 3D mapping literature. For example, the interactive exploded views demonstrated by Niederauer et al. [31] were later used by Chittaro et al. [9] in their WiM to allow viewers to disassemble buildings by foors. Additionally, guidelines for generalisation like those written by Shea and McMaster [41] are just as relevant for designing WiMs as they are in the space of digital cartography. Further, more recent literature such as the fexible multi-scale deformations demonstrated by Pasewaldt et al. [33] allow viewers to bend and distort a 3D map and allow viewers to view a single WiM from multiple angles and resolutions.
We set out to derive a descriptive, comparative, and generative [2] design framework for WiMs — inspired by previous frameworks which have provided terminology for visualisation systems [37], helped organise existing systems [35], and envision new systems [16]. To best identify our fnal dimensions we frst collected papers that contained systems that the authors identifed as WiMs. We collected papers by performing a reverse citation search on the original WiM paper [44], followed by a tree search on collected papers that identifed themselves as containing a WiM. We chose to stop collecting new papers when this process saturated and stopped identifying new papers that contained a WiM, or a system like a WiM. These papers formed the core 25 papers that we based our design dimensions on. While this set is not exhaustive, we believe that it represents a broad representative sample of the space.
From this set of papers we derived our framework through open coding. Initially, the frst author individually coded a small set of papers using a web-based whiteboard tool. All of the coauthors then reviewed these codes, which were adjusted based on group consensus to establish a basis for coding. The frst author then coded the remainder of the papers based on that standard. The other coauthors periodically verifed these groupings to ensure consistency throughout the process. Based on the coding results, we frst identifed 23 potential design dimensions, then refned the fnal set by combining orthogonal dimensions, consolidating similar ones, and scoping our dimensions to just those that describe the form of the replica. Based on this process we combined inter-dependant dimensions like size, scale, and scope. We also generalised overly specifc dimensions into a more general form. While we had originally considered some interactions with WiMs, we decided to remove them from our design dimensions after acknowledging that the set of possible interactions with WiMs is a broad enough topic to merit a design space of its own. Using our fnal set of dimensions we then
re-coded the WiMs from each of the original papers. A summary of this coding can be seen in Figure 2. Finally, after categorising and comparing the papers, we performed a general morphological analysis [38] to identify gaps within our paper set that present opportunities for new WiM designs.
We identifed eight dimensions (size, scope, abstraction, geometry, reference frame, links, multiples, and virtuality) which together characterise the design of WiMs (Figure 1, Figure 2). Because of the tight interrelation between size and scope we consider them together, along with the associated notion of scale. Although other possible design dimensions likely exist, we found that this set captured much of the diversity present in the current research literature.
Size-Scope-Scale encompasses three interdependent properties of a WiM. Size describes the physical dimensions of the miniature replica itself. For example, a replica that can be held in a viewer’s hands may be 30 cm in diameter (Figure 3). Scope describes how much of the world is represented by the replica. For example, the replica could show just a single object, or it could show an entire city (Figure 4). Scale describes the relationship between the size of the model and the space it represents. These relationships are connected — if one is changed, at least one other must also change. For example, if the size of the replica increases from 1 × 1 m to 3 × 3 m the scale would either need to be 3 times larger, the scope would need to encompass more objects, or some combination of the two.
Examples of WiMs exist at a wide variety of sizes, scales, and scopes. One of the smallest is the WiM bounded by a phone made by Mulloni et al. [29] (Figure 3a) measuring only a couple of centimetres across. Most common is a small handheld size; this is the size of the original WiM [44] and is shared by many modern examples, including those developed by Cofey et al. [11] (Figure 3b). At the other end of the spectrum, the WiMs in Gazcón et al.’s ARGeo tool [18] (Figure 3f) exist as an overlay on top of the real visible environment, making the replica efectively hundreds of meters across. The scope of what is contained within a WiM is similarly broad; slice WiM [11, 12] (Figure 4a) was designed for exploring single objects, and was used to navigate within a heart. On the other hand, Li et al.’s large-scale astrophysical environment [26] (Figure 4h) includes WiMs which operate at a galactic scope, and allow viewers to traverse between stars.
Abstraction describes how the replica has been transformed compared to the space it references. There are many diferent abstraction operations that can be performed on a WiM. However, within the papers we surveyed we noted authors creating digital copies of the real world, cartographically generalising , geometrically simplifying, and reducing the scene to just areas or lines to render simplifed versions of the original space (Figure 5).
Within VR it was common for the WiM to be a perfect digital copy of the environment it represented, often relying on the exact same models (as with the miniature rooms used by Pausch et al. [34] (Figure 5a). In AR a digital copy of the real environment was often used instead. In these cases, real world features are typically recreated as a digital model either manually or via automated techniques like photogrammetry. An example of this is the models of famous
CHI ’21, May 8–13, 2021, Yokohama, Japan Danyluk et al.
buildings used by Tatzgern et al. [45] (Figure 5b). A few examples, like the smart home controller made by Seo et al. [40] (Figure 5c) even involved small physical reproductions of the environment.
To reduce clutter and complexity, many systems have used geometric simplifcation for removing and simplifying details in the replica. For instance, the WiM used by Bell et al. [4] (Figure 5d) simplifes most large objects into cubes. In other cases, cartographic generalisation operations can be employed to make replicas more “map-like”. Most commonly this involves simplifying elements of the replica into points, lines, and areas and adjusting their relative visual prominence [27]. Some systems, like Nam et al.’s World-inWedges [30] (Figure 5e) only lightly abstract the WiM. However, more extreme cases may remove almost all content, as in Chittaro et al.’s builing cross-sections [9] (Figure 5f), which excises almost all geometry except for open areas, and Höllerer et al.’s replicas [21] (Figure 5g) which represent spaces using minimalist wireframes.
Geometry describes how the replica is shaped, and is particularly relevant for replicas of large spaces that need to be clipped in order to remain a manageable size, as well as those with many fne details. When the extent of the replica needs to be constrained to a given size, prior systems have employed a variety of approaches including clipping the replica using simple shapes like cylinders or spheres. More complex geometries, like clipping the replica to the boundaries of a building or a room in the model, or to the extent of the current workspace, are also possible. Additionally, non-Euclidean, or disjoint geometry can be used to create efects like exploded building views [31] and curved geometries can be used to create deformations like those demonstrated by Pasewaldt, Trapp, and Döllner [32].
Most WiMs in the collected papers featured simple continuous geometry. Closely clipped WiMs like Nam et al.’s [30] (Figure 6a) Worlds-in-Wedges are shaped to only show the object of interest to
the viewer — in this case their WiM is constrained to just show the was for authors to create WiMs with discontinuous, or irregular country, and not adjacent details like neighbouring countries. Other geometries. Chittaro et al.’s [9] (Figure 6d) BreakAway Map shows authors limited the WiM to a simple shape, for example the WiM how disjoint geometry can be used to separate a building into parts created by Drey [46] (Figure 6b) is rounded as though it is contained to reduce occlusions by automatically splitting the building apart within a cylinder or sphere. It was also common for authors to by foor. Li et al.’s [26] (Figure 6e) Scalable WIM is not bounded bound their WiM to the dimensions of their work space (either at all, expanding infnitely into the scene. While not actually a real or virtual). For example, Arch-Explore by Bruder et al. [7] WiM, Pasewaldt et al. [32] (Figure 6f) create a deformable map (Figure 6c) is constrained by the table it is placed on. Less common that can be bent like a continuous rubber sheet — illustrating how
deforming WiMs could allow viewers to view spaces from multiple perspectives at once.
Reference Frame describes where the replica is positioned and how it is oriented. For instance, it was common to align the WiM based on the physical work table or zone that the WiM was situated in. While we observed that in most cases the reference frame for position was also the reference frame for orientation, this wasn’t always the case. For example, the WiM made by Bell et al. [4] based the horizontal rotation of the WiM on the surrounding room, but determined its position from the viewer. Additionally, some systems, like GeoGate [42], had several reference frames. GeoGate used a handheld token for position, but was oriented with respect to the tabletop environment.
When coding our sample papers we organised them based on the viewer’s proximal space [8]. WiMs in a viewers pericutaneous space are directly on their body, such as the WiM created by Kalkusch et al. [22] (Figure 7a) that showed a map of the foor on the viewer’s wrist, like a watch. WiMs in the peripersonal space arrange themselves based on the viewer’s position, but aren’t directly attached to the viewer — for instance, the city map made by Veas et al. [48] (Figure 7b) always sat in the top right of the viewer’s view in a heads-up display, the WiM made by Stoakley et al. [44] (Figure 7c) sat on a clipboard carried by the viewer, and the foor map made by Mulloni et al. [29] (Figure 7d) was shown on the face of a mobile phone. Finally, WiMs in the viewer’s extrapersonal space are positioned without reference to the viewer — Seo et al.’s [40] (Figure 7e) smart home controller was positioned based on a physical model, Tatzgern et al.’s [45] (Figure 7f) building explorer aligned
their WiM with the building the WiM is a replica of, and the solar system explorer by Li et al. [26] (Figure 7g) had no solid reference at all, letting the WiM foat freely.
Links describe approaches that explicitly connect the replica to the environment (Figure 8). An example of a link would be a building that is highlighted in both the replica and in the environment. The most common link we found was a view frustum in the replica showing the position and orientation of the viewer. Other forms of links we observed include leader lines, and labels.
The majority of WiMs we reviewed did not feature any links at all. Of those that did feature links there was a small variety (Figure 8). A few systems, including Pausch et al.’s 1995 work [34] (Figure 8a) superimposed view frustrums showing the position and orientation of the viewer in the replica. Several others used view planes — introduced in Cofey et al.’s Slice WIM [11] (Figure 8b) — to slice segments of the replica and control the visible area of the scene. Similarly, Staford et al. [43] (Figure 8c) used god hands (enlarged hands that appear in the environment to show where a viewer is pointing on the replica) as one of their god-like interactions. Leader lines that directly tether components of the replica to the corresponding location in the environment also appear in several systems, including Tatzgen et al.’s [45] (Figure 8d). Finally, WiMs can use text to directly identify components, as in Li et al.’s Scalable WIM [26] (Figure 8e) which labels stars in both the replica and space. While these aren’t the only possible forms that links can take, they are the ones that we observed in our set of sample papers.
Multiples characterize cases in which a WiM system includes multiple replicas instead of just one (Figure 9). This can be multiple
replicas all at the same scale, showing diferent states of the WiM, or it can involve one larger, main replica with several small replicas showing subsets of the environment. Only a small minority of papers showcased multiples, but they were used for a variety of applications. The main use was to show subsets of the scene at diferent orientations or positions.
We observed two types of multiples. The frst was recursive multiples, where a smaller version of the replica was embedded within the replica. This was shown by Bluf and Johnston [5] (Figure 9a) who used a camera copy of the environment to create an efectively infnitely recursive WiM using the Droste efect. The other form
of multiples we observed were small multiples, like those used by Tatzgern et al. [45] (Figure 9b) who placed replicas of the replica at diferent rotations to allow the viewer to see a building from many sides at once.
Virtuality describes the WiM’s position within the XR spectrum [28]. While WiMs originally started as a purely VR technique, they have since expanded to include examples across the XR spectrum, including cases in which the replica itself is a physical object.
The frst WiM by Stoakley et al. [44] was created using headset VR, and many afterwards have been as well — including recent
Sc op e Huge Very Large Size Large Moderate Small Very Small Planetary+ Country City Block
Building
Floor
Room
Object
2
2
2
2
2
2
3
Re fe
re nc
e Fr
am e
Huge Very Large
Size
Large Moderate Small Very Small
Free Referent
Scene
Purpose-built Workzone
Device Face
Handheld Token
Viewer
Viewer Bodypart
2
2
2
3
Figure 11: Papers ordered by Size and Scope
implementations such as Bluf and Johnston’s [5] (Figure 10a). However, examples exist for a variety of other platforms including Cave VR [12] (Figure 10b), desktop VR [6] (Figure 10c), headset AR [46] (Figure 10d), projected AR [24] (Figure 10e), and handheld AR [29] (Figure 10f) systems.
We observed a number of relationships between the various dimensions, as well as gaps in the literature for both individual dimensions and combinations of dimensions. Here we identify some of these patterns and gaps, and we will later look more closely at potential applications that fll these gaps.
Size vs. Scope. While we have identifed size, scale, and scope as a set of interdependent dimensions, there is a strong positive correlation between the size of a WiM, and its scope — with developers typically using larger WiMs to represent larger and more complex regions (Figure 11). By contrast, the set of systems we examined contain no examples of small or very small WiMs whose scope showed anything larger than a single building. Surprisingly we also saw no examples of large WiMs whose scope was smaller than the foor of a building, although the interactive virtual globes in tools like Google Earth VR [23] clearly demonstrate the value of this combination. While in most cases it is practical to pair large sizes with broad scopes there may be opportunities where straying from these pattern can be benefcial. As a temporary, or transitional state, having a large WiM with a small scope could be used to highlight an object of interest, such as greatly expanding the sign for a bus stop in the replica as the viewer gets within viewing distance of the actual sign. As another example, if many small multiples of individual small WiMs with broad scopes are used together, the size of each can be controlled with a focus + context operation like
Figure 12: Papers ordered by Size and Reference Frame
a fsh eye menu [3], magnifying the WiM in active use, but keeping the other smaller WiMs in view.
Size vs. Reference Frame. There is a common relationship between the size of a WiM, and the reference frame it has been given (Figure 12). A WiM with a reference frame that is close to, or a part of the body (pericutaneous, peripersonal) is more likely to also be small. While a WiM with a reference frame that is a part of the environment, or the environment itself (extrapersonal), is more likely to be large. Both of these can be explained from a practical standpoint, a WiM that is several meters in diameter would be unwieldy when placed on a viewers wrist. Further, if a WiM that was only a few centimetres in diameter was placed on a boardroom table many meters wide there would be a large amount of wasted space. However, these impracticalities can be overcome. For example, Tatzgern et al. [45] explore a small WiM that has an extrapersonal reference frame by physically distancing the replica from the reference frame — while the referent is large, its apparent size is comparable to the WiM. At the other end of the spectrum, a large WiM can be placed within a viewer’s personal space by distributing it around their body — for instance, by projecting it in a torus around their torso, or distributing it across their limbs (which we explore in subsection 6.2).
Size vs. Geometry. We observed that in most cases small WiMs are tightly bounded, often clipped to just the object of interest itself (Figure 13). In contrast, larger WiMs are often bounded by a feature of the environment (such as a work table). Although WiMs at all sizes are bounded by simple shapes. At the extreme end, any unbounded WiM showing a large area or object will consume considerable space — as it has no solid boundary to constrain it. However, even when considering a large WiM it can be benefcial to restrict the geometry to just the object of interest. For example, for a team collaborating around a WiM of a to-be-built building, reducing the WiM to just the building of interest could help manage occlusion from multiple vantage points.
G eo m et ry Huge Very Large Size Large Moderate Small Very Small Disjoint In nite Clipped to Workspace
Clipped to Simple Shape
Clipped to Focus
2
2
2
263
Figure 13: Papers ordered by Size and Geometry
Vi rt
ua lit
y
Just Lines Just Areas
Abstraction
Cartographic Generalisation Geometric Simpli cation PhysicalCopy Digital Recreation
Headset AR
Handheld AR
Projected AR
Desktop VR
Cave VR
Headset VR
2
2
3
Perfect Recreation
2
2 5
Figure 14: Papers ordered by Abstraction and Virtuality
View Frustum
View Planes
Godhands
Leader Lines
Labels
None
Links
16
Small Multiples Recursive Multiples None
Multiples
21
Viewer Bodypart
Viewer
Handheld Token
Device Face
Purpose-built Workzone
Scene
Free Referent
Reference Frame
Figure 15: WiM counts by Reference Frame
Figure 16: WiMs counts by Link type Figure 17: WiMs counts by Multiples
Abstraction vs. Virtuality. WiMs made for VR tend to feature less abstraction than those made for AR (Figure 14). We suspect that this has more to do with the current capabilities of the respective technologies than a practical relationship between the dimensions. It is currently much easier to create a replica that is a perfect or near perfect copy of the environment in VR than it is in AR. However, as technologies like photogrammetry improve, and as AR headset technology matures and becomes more powerful this gap is likely to close. With the ability to easily create realistic views of real places, applications like third person bird’s eye views [17] will likely become more realistic outside of VR. On the fip side, while VR instances of WiMs are currently able to feature replicas that are perfect recreations of the VR environment, simplifed or generalised replicas can still help viewers focus on the most important features of the replica [41].
Links. Links are a heavily underrepresented dimension, with 16 out of 25 of the WiMs we reviewed not featuring any explicit links between the replica and the space (Figure 16). Further, the
variety of links that we did observe was not extensive — including only view frustums, view planes, god hands, leader lines, and labels. The sparsity of examples indicates that there remain many exciting opportunities in this space. One medium which already features a wide variety of links is video games [13] and many examples of linking and pointing techniques from this domain seem likely to work well with WiMs. These include approaches like diegetic cues, which are common in video games and could provide simple and semantically meaningful links between WiMs and environments. For example, a WiM of a city street could turn on the streetlamps along the viewer’s path to unobtrusively show their progress in the real space.
Multiples. Similarly, multiples are another heavily underrepresented dimension with only 4 out of the 25 papers we reviewed featuring them (Figure 17). These few examples we saw focused on showing either multiple views of the same building from diferent orientations [45] or location based subsets [14]. However, given the widespread and successful use of small multiples techniques in data
visualization tools, there are likely many more exciting possibilities for WiMs that use multiples. For example, a large single replica combined with small multiples [15] of it could be used to show the history of a viewer’s interaction with a WiM.
Reference Frame. While WiMs of all sorts featured extrapersonal reference frames, very few utilised peripersonal or pericutaneous reference frames (Figure 15). Those few that did tended to be used with small, tightly scoped, or tightly clipped WiMs. There exists ample space to explore WiMs that sit within the viewer’s personal space, along many dimensions (as noted above in Size vs. Reference Frame).
Other. Interestingly, several pairs of dimensions in our framework did not show any obvious relationship to one another. Abstraction and geometry were one such pair — during the process of abstraction the available geometry of the WiM may also be reduced. For example, if a WiM has been cartographically generalised to only include the roads of a scene, then the geometry will appear to be clipped to the focus (in this case the roads) even if the chosen geometry is actually less restrictive. Conversely, a WiM showing a building that is bounded to a short cylinder will appear as though the roof has been abstracted away.
Another pair that displayed only a loose connection was geometry and virtuality. The means used to create the virtual environment infuences the possible geometry of a WiM. For example, due to the limited projection space it is more difcult to create an infnite WiM by using projected AR then it would be to create an infnite WiM using headset VR. However, many of the examples of simplifed geometry we observe refected historical technical limitations of XR devices rather than contemporary ones.
To help demonstrate the generative utility of our framework, in this section we illustrate several novel WiMs described as a function of our design dimensions. In section 5 we identifed a number of gaps present within the papers we reviewed. We ft our proposed WiMs within those gaps, addressing unique design challenges.
When analysing the trends and gaps within current WiMs we noted that the majority of WiMs don’t feature links. To help fll that gap, we propose a WiM that uses highlighting in a way that would
be difcult without a WiM (Table 1). In this example the WiM features an architectural model of a building that is still under construction. At the construction site the replica can be used to highlight components of the unfnished building. When a viewer selects a piece of the building on the replica, the corresponding component of the building in the environment is also highlighted. In circumstances where a component is not shared between the two (such as a part of the building that is not built yet, or a detail of the building too small to be added to the model) the area where that component would be is instead highlighted. In Figure 18 a viewer is selecting the roof at the top of the replica, in the background they can see the roof being highlighted on a AR overlay of the building. By using these shared spatial highlights a viewer can get an idea of the footprint of a building on-site during construction. For example, when preparing marketing material for the new building, a Realtor could use the highlights to determine what pieces of the skyline will be visible once the building is complete.
This example was inspired by the use of scale models in architecture [20]. As a result, our choices for many of the design dimensions (including size, scope, abstraction, and geometry) refect the conventions and properties of the physical models produced by architecture frms. For the reference frame, we chose free referent,
refecting the fact that scale building models can be used at a variety of locations both at a building site or (more frequently) at the design studio and don’t require a specifc spatial relationship with the building. Finally, we imagined this example as a headset AR application, which would allow the viewer to use both hands to interact with the model and with other tools, and could support deployment in construction settings.
In the existing literature, we noted the absence WiMs that were both pericutaneous and had a large size (Table 1). To examine this unique combination, we propose a system that takes advantage of the viewer’s entire body to host a large WiM (Figure 19). In this example the buildings of a college campus are spread across the viewer’s body. Buildings that are close to the viewer are placed on parts of their body that are easy to reference (like their forearms) whereas buildings that are far away are placed on less reachable, but still visible parts of their body (like their shins). Buildings behind or otherwise outside the viewer’s feld of vision are likewise shifted to less-visible locations on the body (such as their calves) where they can be seen peripherally. This approach cartographically generalises important landmarks including prominent buildings using an approach similar to the automatic tourist maps proposed by Grabler et al. [19], highlighting the most important features of the campus and de-emphasising the spaces in between them. By viewing the WiM with a headset AR device the viewer could easily reference buildings in their immediate vicinity, while maintaining a peripheral knowledge of the entire campus. This could be particularly useful while the viewer is walking, allowing them to use their body’s sense of proprioception [8] to reference the replica. Such an approach could also be useful in crowded spaces, ftting tightly to the viewer’s body when most large AR objects would be occluded or intersected by the surrounding environment.
Our analysis also highlighted a shortage of WiMs that incorporated multiples (Table 1). To prompt the development of more systems that incorporate multiple simultaneous WiMS, we propose an interface that uses multiples to show a mountain hike at two levels of detail (Figure 20) in the style of a traditional overview+detail visualisation [10]. In this example, the system includes two multiples, each showing the same hiking route. The large multiple on the left side of the screen (Figure 20) shows the entire mountain that is being hiked, while the smaller multiple on the right side of the screen (Figure 20) is clipped to focus on just the current trail segment. This pairing would allow viewers to simultaneously see their progress up the mountain as well as a more detailed bird’s eye view of the portion of the hike that they are immediately concerned with. Mobile AR might appropriate for this application as a phone or other device could be easily stowed by the viewer during more physically involved portions of their hike. Finally, this WiM uses the viewer as its reference frame so that it is available throughout the hike.
In addition to our specifc example WiMs, we provide more general advice on choosing dimensions for a WiM based on application domain, based on our observations from prior work. We observed 5 distinct application domains amongst the WiMs we coded — wayfnding, collaboration, visualisation, navigation, and control space (Table 2) — and discuss two important dimensions to consider for each application domain.
Wayfnding: In a wayfnding application the WiM serves as an overview that viewers use to identify and follow paths between locations. Because wayfnding tools typically need to move through space along with the viewer, WiMs designed for this purpose are likely to lend themselves to pericutaneous or peripersonal reference
frames. Similarly, they may beneft from small sizes and constrained scopes that reduce overlap with and occlusion of the environment.
Collaboration: In applications that use collaborative WiMs, multiple viewers may examine or interact with the same replica simultaneously. As a result, we expect that larger replicas with extrapersonal reference frames will usually be preferable. Further, clipping the geometry to a focus area or simple shape can allow multiple viewers to more freely move and interact around the WiM.
Visualisation: The visualization applications we observed cover a wide range of data types, visual encodings, and contexts of use, making general guidance for these systems difcult. However, the widespread use of techniques like small multiples [15] and brushingand-linking [39] in visualisation more broadly strongly suggests the value of incorporating multiples and links in WiM systems intended to support data exploration and analysis.
Navigation: WiMs designed for navigation allow viewers to change their position in the full-sized (typically virtual) environment by using the miniature replica. A key concern is ensuring that the scale of the replica allows for precise pointing [49]. In addition, non-euclidean or distorted geometries that enable viewers to navigate to occluded areas, including building interiors [9], may be advantageous.
Control Space: A WiM designed as a control space enables the viewer to control elements of their environment using the replica. If the replica and environment difer considerably in scale it can be useful to use abstraction to increase the size or visibility of interactive elements, or to simplify away non-interactive ones. As with navigation, geometries that reduce occlusion can increase viewers’ ability to access and interact with more of the control space at once.
Worlds-in-Miniature represent a promising and extremely relevant area for XR research, and one which is well-positioned to build on approaches from a variety of related felds. Not only are WiMs one of the earliest interaction metaphors introduced for virtual reality, they also share many properties with the kinds of overview+detail interfaces frequently used in data visualisation. Because they often
take the forms of maps and terrain models, they also have the potential to draw on recent advances in digital cartography. At the same time, the vast space of diferent WiM designs suggests new uses in a wide variety of diferent application areas.
Our framework for describing WiM systems showcases the diversity of past approaches, but also highlights just how much of the design space remains unexamined. Many of these unexplored points, including the examples in section 6 refect promising opportunities for near-term research and design. Others highlight challenges both in our current tools and technology. For example, varying the level of abstraction in WiMs still represents a challenge in both VR and AR, and most conceptual abstraction (and even much of the visual abstraction) used in current systems is still handled manually by designers. Meanwhile, creating truly realistic WiMs remains challenging because current platforms lack both the data and processing power necessary to create high-fdelity representations of most scenes. This is especially challenging for augmented- and mixed-reality applications, given the host of challenges associated with capturing, rendering, and updating visually accurate and up-to-date representations of physical environments. However, rapidly maturing photogrammetry and real-time scene reconstruction approaches mean that realistic live WiMs of real-world spaces will likely be possible in the near future. Parallel advances in XR headsets and related display technologies will also make using these WiMs in real-world environments increasingly practical. With that in mind, exploring new WiM designs, interactions, and application areas represents a rich area for research both now and for the foreseeable future.
This research was undertaken, in part, thanks to funding from the Canada Research Chairs Program. Thank you to all of our colleagues who helped provide examples of WiMs in the research literature, in popular media, and around the world, and who granted permission to reproduce their fgures.
[1] C. Andújar, P. Vázquez, and M. Fairén. 2004. Way-Finder: guided
tours through complex walkthrough models. Computer Graphics Forum 23, 3 (2004), 499–508. https://doi.org/10.1111/j.1467-8659.2004. 00781.x _eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/j.14678659.2004.00781.x. [2] Michel Beaudouin-Lafon. 2004. Designing interaction, not interfaces. In Proceedings of the working conference on Advanced visual interfaces (AVI ’04). Association for Computing Machinery, New York, NY, USA, 15–22. https://doi.org/10.1145/ 989863.989865 [3] Benjamin B. Bederson. 2000. Fisheye Menus. Association for Computing Machinery, San Diego, CA, USA. 217–225 pages. [4] Blaine Bell, Tobias Höllerer, and Steven Feiner. 2002. An annotated situationawareness aid for augmented reality. In Proceedings of the 15th annual ACM symposium on User interface software and technology - UIST ’02. ACM Press, New York, New York, USA, 213–216. https://doi.org/10.1145/571985.572017 [5] Andrew Bluf and Andrew Johnston. 2019. Don’t Panic: Recursive Interactions in a Miniature Metaworld. In The 17th International Conference on Virtual-Reality Continuum and its Applications in Industry. ACM, Brisbane QLD Australia, 1–9. https://doi.org/10.1145/3359997.3365682 [6] Andrea Bonsch, Sebastian Freitag, and Torsten W. Kuhlen. 2016. Automatic generation of world in miniatures for realistic architectural immersive virtual environments. In 2016 IEEE Virtual Reality (VR). IEEE, Greenville, SC, USA, 155– 156. https://doi.org/10.1109/VR.2016.7504700 ISSN: 2375-5334. [7] Gerd Bruder, Frank Steinicke, and Klaus H. Hinrichs. 2009. Arch-Explore: A natural user interface for immersive architectural walkthroughs. In 2009 IEEE Symposium on 3D User Interfaces. IEEE, Lafayette, Louisiana, US, 75–82. https: //doi.org/10.1109/3DUI.2009.4811208 [8] Xiang ’Anthony’ Chen, Nicolai Marquardt, Anthony Tang, Sebastian Boring, and Saul Greenberg. 2012. Extending a mobile device’s interaction space through body-centric interaction. In Proceedings of the 14th international conference on Human-computer interaction with mobile devices and services (MobileHCI ’12). Association for Computing Machinery, New York, NY, USA, 151–160. https: //doi.org/10.1145/2371574.2371599 [9] L. Chittaro, V.K. Gatla, and S. Venkataraman. 2005. The Interactive 3D BreakAway Map: a navigation and examination aid for multi-foor 3D worlds. In 2005 International Conference on Cyberworlds (CW’05). IEEE, Singapore, Singapore, 8 pp.–66. https://doi.org/10.1109/CW.2005.88 [10] Andy Cockburn, Amy Karlson, and Benjamin B. Bederson. 2008. A review of overview+detail, zooming, and focus+context interfaces. Comput. Surveys 41, 1 (Dec. 2008), 1–31. https://doi.org/10.1145/1456650.1456652 [11] Dane Cofey, Nicholas Malbraaten, Trung Le, Iman Borazjani, Fotis Sotiropoulos, and Daniel F. Keefe. 2011. Slice WIM: a multi-surface, multi-touch interface for overview+detail exploration of volume datasets in virtual reality. In Symposium on Interactive 3D Graphics and Games (I3D ’11). Association for Computing Machinery, New York, NY, USA, 191–198. https://doi.org/10.1145/1944745.1944777 [12] Dane Cofey, Nicholas Malbraaten, Trung Bao Le, Iman Borazjani, Fotis Sotiropoulos, Arthur G. Erdman, and Daniel F. Keefe. 2011. Interactive Slice WIM: Navigating and Interrogating Volume Data Sets Using a Multisurface, Multitouch VR Interface. IEEE Transactions on Visualization and Computer Graphics 18, 10 (Oct. 2011), 1614–1626. https://doi.org/10.1109/TVCG.2011.283 [13] Kody R. Dillman, Terrance Tin Hoi Mok, Anthony Tang, Lora Oehlberg, and Alex Mitchell. 2018. A Visual Interaction Cue Framework from Video Game Environments for Augmented Reality. In Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems (CHI ’18). Association for Computing Machinery, New York, NY, USA, 1–12. https://doi.org/10.1145/3173574.3173714 [14] T Todd Elvins, David R Nadeau, Rina Schul, and David Kirsh. 1998. Worldlets: 3D thumbnails for 3D browsing. In Proceedings of the SIGCHI Conference on Human Factors in Computing systems. Association for Computing Machinery, Los Angeles, CA, USA, 163–170. [15] Stef van den Elzen and Jarke J. van Wijk. 2013. Small Multiples, Large Singles: A New Approach for Visual Data Exploration. Computer Graphics Forum 32, 3pt2 (2013), 191–200. https://doi.org/10.1111/cgf.12106 _eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/cgf.12106. [16] Barrett Ens, Juan David Hincapié-Ramos, and Pourang Irani. 2014. Ethereal planes: a design framework for 2D information space in 3D mixed reality environments. In Proceedings of the 2nd ACM symposium on Spatial user interaction (SUI ’14). Association for Computing Machinery, New York, NY, USA, 2–12. https://doi. org/10.1145/2659766.2659769 [17] Shinji Fukatsu, Yoshifumi Kitamura, Toshihiro Masaki, and Fumio Kishino. 1998. Intuitive Control of Bird’s Eye Overview Images for Navigation in an Enormous Virtual Environment. In Proceedings of the ACM Symposium on Virtual Reality Software and Technology (VRST ’98). ACM, New York, NY, USA, 67–76. https: //doi.org/10.1145/293701.293710 [18] Nicolás F. Gazcón, Juan M. Trippel Nagel, Ernesto A. Bjerg, and Silvia M. Castro. 2018. Fieldwork in Geosciences assisted by ARGeo: A mobile Augmented Reality system. Computers & Geosciences 121 (Dec. 2018), 30–38. https://doi.org/10.1016/ j.cageo.2018.09.004
[19] Floraine Grabler, Maneesh Agrawala, Robert W. Sumner, and Mark Pauly. 2008. Automatic generation of tourist maps. ACM Transactions on Graphics 27, 3 (Aug. 2008), 1–11. https://doi.org/10.1145/1360612.1360699 [20] Carmen Hull and Wesley Willett. 2017. Building with Data: Architectural Models as Inspiration for Data Physicalization. In Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems (CHI ’17). Association for Computing Machinery, New York, NY, USA, 1217–1264. https://doi.org/10.1145/3025453. 3025850 [21] Tobias Höllerer, Steven Feiner, Drexel Hallaway, Blaine Bell, Marco Lanzagorta, Dennis Brown, Simon Julier, Yohan Baillot, and Lawrence Rosenblum. 2001. User interface management techniques for collaborative mobile augmented reality. Computers & Graphics 25, 5 (Oct. 2001), 799–810. https://doi.org/10.1016/S00978493(01)00122-4 [22] M. Kalkusch, T. Lidy, N. Knapp, G. Reitmayr, H. Kaufmann, and D. Schmalstieg. 2002. Structured visual markers for indoor pathfnding. In The First IEEE International Workshop Agumented Reality Toolkit,. IEEE, Darmstadt, Germany, Germany, 8 pp.–. https://doi.org/10.1109/ART.2002.1107018 [23] Dominik P. Käser, Evan Parker, Adam Glazier, Mike Podwal, Matt Seegmiller, Chun-Po Wang, Per Karlsson, Nadav Ashkenazi, Joanna Kim, Andre Le, Matthias Bühlmann, and Joshua Moshier. 2017. The Making of Google Earth VR. In ACM SIGGRAPH 2017 Talks (Los Angeles, California) (SIGGRAPH ’17). Association for Computing Machinery, New York, NY, USA, Article 63, 2 pages. https: //doi.org/10.1145/3084363.3085094 [24] Joseph J. LaViola, Daniel Acevedo Feliz, Daniel F. Keefe, and Robert C. Zeleznik. 2001. Hands-free multi-scale navigation in virtual environments. In Proceedings of the 2001 symposium on Interactive 3D graphics (I3D ’01). Association for Computing Machinery, New York, NY, USA, 9–15. https://doi.org/10.1145/364338.364339 [25] Nico Li, Wesley Willett, Ehud Sharlin, and Mario Costa Sousa. 2017. Visibility perception and dynamic viewsheds for topographic maps and models. In Proceedings of the 5th Symposium on Spatial User Interaction - SUI ’17. ACM Press, Brighton, United Kingdom, United Kingdom, 39–47. https://doi.org/10.1145/ 3131277.3132178 [26] Yinggang Li, Chi-wing Fu, and Andrew Hanson. 2006. Scalable WIM: Efective Exploration in Large-scale Astrophysical Environments. IEEE Transactions on Visualization and Computer Graphics 12, 5 (Sept. 2006), 1005–1012. https://doi.org/10.1109/TVCG.2006.176 Conference Name: IEEE Transactions on Visualization and Computer Graphics. [27] Steve Manson. 2017. Mapping, Society, and Technology. University of Minnesota Libraries Publishing, Minneapolis ,Minnesota, USA. https://open.umn.edu/ opentextbooks/textbooks/mapping-society-and-technology [28] Paul Milgram and Fumio Kishino. 1994. A Taxonomy of Mixed Reality Visual Displays. IEICE Trans. Information Systems vol. E77-D, no. 12 (1994), 1321–1329. [29] Alessandro Mulloni, Hartmut Seichter, and Dieter Schmalstieg. 2012. Indoor navigation with mixed reality world-in-miniature views and sparse localization on mobile devices. In Proceedings of the International Working Conference on Advanced Visual Interfaces (AVI ’12). Association for Computing Machinery, New York, NY, USA, 212–215. https://doi.org/10.1145/2254556.2254595 [30] Jung Who Nam, Krista McCullough, Joshua Tveite, Maria Molina Espinosa, Charles H. Perry, Barry T. Wilson, and Daniel F. Keefe. 2019. Worlds-inWedges: Combining Worlds-in-Miniature and Portals to Support Comparative Immersive Visualization of Forestry Data. In 2019 IEEE Conference on Virtual Reality and 3D User Interfaces (VR). IEEE, Osaka, Japan, 747–755. https: //doi.org/10.1109/VR.2019.8797871 ISSN: 2642-5254. [31] Christopher Niederauer, Mike Houston, Maneesh Agrawala, and Greg Humphreys. 2003. Non-invasive interactive visualization of dynamic architectural environments. In Proceedings of the 2003 symposium on Interactive 3D graphics (I3D ’03). Association for Computing Machinery, New York, NY, USA, 55–58. https://doi.org/10.1145/641480.641493 [32] Sebastian Pasewaldt, Amir Semmo, Matthias Trapp, and Jürgen Döllner. 2014. Multi-perspective 3D panoramas. International Journal of Geographical Information Science 28, 10 (2014), 2030–2051. https://doi. org/10.1080/13658816.2014.922686 Publisher: Taylor & Francis _eprint: https://doi.org/10.1080/13658816.2014.922686. [33] Sebastian Pasewaldt, Matthias Trapp, and Jürgen Döllner. 2011. Multiscale visualization of 3D geovirtual environments using view-dependent multi-perspective views. Journal of WSCG 19 (2011), 111–118. http://dspace5.zcu.cz/handle/11025/ 1245 Accepted: 2013-02-13T13:26:25Z Publisher: Václav Skala - UNION Agency. [34] Randy Pausch, Tommy Burnette, Dan Brockway, and Michael E Weiblen. 1995. Navigation and Locomotion in Virtual Worlds via Flight into Hand-held Miniatures. In Proceedings of the 22Nd Annual Conference on Computer Graphics and Interactive Techniques (SIGGRAPH ’95). ACM, 399–400. https://doi.org/10.1145/ 218380.218495 [35] C. Plaisant, D. Carr, and B. Shneiderman. 1995. Image-browser taxonomy and guidelines for designers. IEEE Software 12, 2 (March 1995), 21–32. https://doi. org/10.1109/52.368260 Conference Name: IEEE Software. [36] M. E. Portman, A. Natapov, and D. Fisher-Gewirtzman. 2015. To go where no man has gone before: Virtual reality in architecture, landscape architecture and environmental planning. Computers, Environment and Urban Systems 54 (Nov.
A Design Space Exploration of Worlds in Miniature
2015), 376–384. https://doi.org/10.1016/j.compenvurbsys.2015.05.001 [37] Blaine A. Price, Ronald M. Baecker, and Ian S. Small. 1993. A Principled Taxonomy
of Software Visualization. Journal of Visual Languages & Computing 4, 3 (Sept. 1993), 211–266. https://doi.org/10.1006/jvlc.1993.1015 [38] Tom Ritchey. 1998. General morphological analysis. In 16th euro conference on operational analysis, Vol. 41. [39] Jonathan C Roberts. 2007. State of the art: Coordinated & multiple views in exploratory visualization. In Fifth International Conference on Coordinated and Multiple Views in Exploratory Visualization (CMV 2007). IEEE, 61–71. https: //doi.org/10.1109/CMV.2007.20 [40] Dong Woo Seo, Hyun Kim, Jae Sung Kim, and Jae Yeol Lee. 2016. Hybrid realitybased user experience and evaluation of a context-aware smart home. Computers in Industry 76 (Feb. 2016), 11–23. https://doi.org/10.1016/j.compind.2015.11.003 [41] K Stuart Shea and Robert B McMaster. 1989. Cartographic generalization in a digital environment: When and how to generalize. In Proceedings Auto-Carto 9. Citeseer. [42] Seung Youb Ssin, James A. Walsh, Ross T. Smith, Andrew Cunningham, and Bruce H. Thomas. 2019. GeoGate: Correlating Geo-Temporal Datasets Using an Augmented Reality Space-Time Cube and Tangible Interactions. In 2019 IEEE Conference on Virtual Reality and 3D User Interfaces (VR). IEEE, 210–219. https: //doi.org/10.1109/VR.2019.8797812 ISSN: 2642-5254. [43] Aaron Staford, Wayne Piekarski, and Bruce H. Thomas. 2006. Implementation of god-like interaction techniques for supporting collaboration between outdoor AR and indoor tabletop users. In 2006 IEEE/ACM International Symposium on Mixed and Augmented Reality. IEEE, 165–172. https://doi.org/10.1109/ISMAR. 2006.297809
CHI ’21, May 8–13, 2021, Yokohama, Japan
[44] Richard Stoakley, Matthew J Conway, and Randy Pausch. 1995. Virtual Reality on a WIM: Interactive Worlds in Miniature. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems (CHI ’95). ACM Press/Addison-Wesley Publishing Co., New York, NY, USA, 265–272. https://doi.org/10.1145/223904. 223938 [45] Markus Tatzgern, Raphael Grasset, Eduardo Veas, Denis Kalkofen, Hartmut Seichter, and Dieter Schmalstieg. 2015. Exploring real world points of interest: Design and evaluation of object-centric exploration techniques for augmented reality. Pervasive and Mobile Computing 18 (April 2015), 55–70. https://doi.org/ 10.1016/j.pmcj.2014.08.010 [46] Drey Tobias. 2018. Data Visualisation using Augmented Reality with a Focus set on Head Mounted Displays and Collaborative Tasks. International Symposium on NDT in Aerospace 10 (2018), 1–9. [47] Ramón Trueba, Carlos Andujar, and Ferran Argelaguet. 2009. Complexity and Occlusion Management for the World-in-Miniature Metaphor. In Smart Graphics, Andreas Butz, Brian Fisher, Marc Christie, Antonio Krüger, Patrick Olivier, and Roberto Therón (Eds.). Springer Berlin Heidelberg, Berlin, Heidelberg, 155–166. [48] Eduardo Veas, Raphael Grasset, Ernst Kruijf, and Dieter Schmalstieg. 2012. Extended Overview Techniques for Outdoor Augmented Reality. IEEE Transactions on Visualization and Computer Graphics 18, 4 (April 2012), 565–572. https://doi.org/10.1109/TVCG.2012.44 Conference Name: IEEE Transactions on Visualization and Computer Graphics. [49] C A Wingrave, Y Haciahmetoglu, and D A Bowman. 2006. Overcoming World in Miniature Limitations by a Scaled and Scrolling WIM. In 3D User Interfaces, 2006. 3DUI 2006. IEEE Symposium on, Vol. 2006. IEEE, 11–16.
